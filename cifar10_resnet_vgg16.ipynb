{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-resnet/vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0geZyTdOLhZ8fKWr5i0u0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuchun-nii/DP_test/blob/main/cifar10_resnet_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHkwctm3ff5c"
      },
      "source": [
        "ResNet v1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taeGpL6qkBy5",
        "outputId": "19e3e3f9-d0ce-4fbd-d59d-96ab783ab883"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import keras\r\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation,AveragePooling2D, Input, Flatten\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras import backend as K\r\n",
        "from keras.models import Model\r\n",
        "from keras.datasets import cifar10\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "#設置參數\r\n",
        "batch_size = 32\r\n",
        "epochs = 200\r\n",
        "data_augmentation = True #數據增強\r\n",
        "num_classes = 10\r\n",
        "subtract_pixel_mean = True# Subtracting pixel mean improves accuracy(減去像素均值可提高準確性)\r\n",
        "n=3 # Model parameter\r\n",
        "\r\n",
        "# Model version\r\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\r\n",
        "version = 1\r\n",
        "\r\n",
        "#根據前面設的模型參數n來計算深度\r\n",
        "if version == 1:\r\n",
        "    depth = n * 6 + 2\r\n",
        "elif version == 2:\r\n",
        "    depth = n * 9 + 2\r\n",
        "\r\n",
        "# Model name, depth and version\r\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\r\n",
        "\r\n",
        "# Loading data\r\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n",
        "\r\n",
        "# Input image dimensions.\r\n",
        "input_shape = x_train.shape[1:]\r\n",
        "\r\n",
        "# Normalize data.\r\n",
        "x_train = x_train.astype('float32') / 255\r\n",
        "x_test = x_test.astype('float32') / 255\r\n",
        "\r\n",
        "# 如果啟用減法像素均值(subtract pixel mean)\r\n",
        "if subtract_pixel_mean:\r\n",
        "    x_train_mean = np.mean(x_train, axis=0)\r\n",
        "    x_train -= x_train_mean\r\n",
        "    x_test -= x_train_mean\r\n",
        "\r\n",
        "print('x_train shape:', x_train.shape)\r\n",
        "print(x_train.shape[0], 'train samples')\r\n",
        "print(x_test.shape[0], 'test samples')\r\n",
        "print('y_train shape:', y_train.shape)\r\n",
        "\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "\r\n",
        "def lr_schedule(epoch):\r\n",
        "#Learning Rate Schedule:預計在80,120,160,180 epochs後降低learning rate.\r\n",
        "#在訓練過程中，作為回調(callbacks)的一部份，自動調用每個epoch\r\n",
        "    lr = 1e-3\r\n",
        "    if epoch > 180:\r\n",
        "        lr *= 0.5e-3\r\n",
        "    elif epoch > 160:\r\n",
        "        lr *= 1e-3\r\n",
        "    elif epoch > 120:\r\n",
        "        lr *= 1e-2\r\n",
        "    elif epoch > 80:\r\n",
        "        lr *= 1e-1\r\n",
        "    print('Learning rate: ', lr)\r\n",
        "    return lr\r\n",
        "\r\n",
        "\r\n",
        "def resnet_layer(inputs,num_filters=16,kernel_size=3,strides=1,activation='relu',batch_normalization=True,conv_first=True):\r\n",
        "    #conv_first(bool): conv-bn-activation(True)or bn-activation-conv(False)\r\n",
        "    conv = Conv2D(num_filters,kernel_size=kernel_size,strides=strides,padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-4))\r\n",
        "\r\n",
        "    x = inputs\r\n",
        "    if conv_first:\r\n",
        "        x = conv(x)\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "    else:\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "        x = conv(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\r\n",
        "    \"\"\"\r\n",
        "    ResNet Version 1 Model builder [a]\r\n",
        "\r\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n",
        "    Last ReLU is after the shortcut connection.\r\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled) by a convolutional layer with strides=2, while the number of filters is doubled. Within each stage, the layers have the same number filters and the same number of filters.\r\n",
        "    Features maps sizes:\r\n",
        "    stage 0: 32x32, 16\r\n",
        "    stage 1: 16x16, 32\r\n",
        "    stage 2:  8x8,  64\r\n",
        "    \"\"\"\r\n",
        "    if (depth - 2) % 6 != 0:\r\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n",
        "    # Start model definition.\r\n",
        "    num_filters = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 6)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    x = resnet_layer(inputs=inputs)\r\n",
        "    # Instantiate the stack of residual units\r\n",
        "    for stack in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            strides = 1\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                strides = 2  # downsample\r\n",
        "            y = resnet_layer(inputs=x,num_filters=num_filters,strides=strides)\r\n",
        "            y = resnet_layer(inputs=y,num_filters=num_filters,activation=None)\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                # linear projection residual shortcut connection to match\r\n",
        "                # changed dims\r\n",
        "                x = resnet_layer(inputs=x,num_filters=num_filters,kernel_size=1,strides=strides,activation=None,batch_normalization=False)\r\n",
        "            x = keras.layers.add([x, y])\r\n",
        "            x = Activation('relu')(x)\r\n",
        "        num_filters *= 2\r\n",
        "\r\n",
        "    # Add classifier on top.\r\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\r\n",
        "    x = AveragePooling2D(pool_size=8)(x)\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,activation='softmax',kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    # Instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\r\n",
        "    \"\"\"\r\n",
        "    ResNet Version 2 Model builder [b]\r\n",
        "\r\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\r\n",
        "    bottleneck layer\r\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\r\n",
        "    Second and onwards shortcut connection is identity.\r\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\r\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\r\n",
        "    doubled. Within each stage, the layers have the same number filters and the\r\n",
        "    same filter map sizes.\r\n",
        "    Features maps sizes:\r\n",
        "    conv1  : 32x32,  16\r\n",
        "    stage 0: 32x32,  64\r\n",
        "    stage 1: 16x16, 128\r\n",
        "    stage 2:  8x8,  256\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    if (depth - 2) % 9 != 0:\r\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\r\n",
        "    # Start model definition.\r\n",
        "    num_filters_in = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 9)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\r\n",
        "    x = resnet_layer(inputs=inputs,num_filters=num_filters_in,conv_first=True)\r\n",
        "\r\n",
        "    # Instantiate the stack of residual units\r\n",
        "    for stage in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            activation = 'relu'\r\n",
        "            batch_normalization = True\r\n",
        "            strides = 1\r\n",
        "            if stage == 0:\r\n",
        "                num_filters_out = num_filters_in * 4\r\n",
        "                if res_block == 0:  # first layer and first stage\r\n",
        "                    activation = None\r\n",
        "                    batch_normalization = False\r\n",
        "            else:\r\n",
        "                num_filters_out = num_filters_in * 2\r\n",
        "                if res_block == 0:  # first layer but not first stage\r\n",
        "                    strides = 2    # downsample\r\n",
        "\r\n",
        "            # bottleneck residual unit\r\n",
        "            y = resnet_layer(inputs=x,num_filters=num_filters_in,kernel_size=1,strides=strides,activation=activation,batch_normalization=batch_normalization,conv_first=False)\r\n",
        "            y = resnet_layer(inputs=y,num_filters=num_filters_in,conv_first=False)\r\n",
        "            y = resnet_layer(inputs=y,num_filters=num_filters_out,kernel_size=1,conv_first=False)\r\n",
        "            if res_block == 0:\r\n",
        "                # linear projection residual shortcut connection to match\r\n",
        "                # changed dims\r\n",
        "                x = resnet_layer(inputs=x,num_filters=num_filters_out,kernel_size=1,strides=strides,activation=None,batch_normalization=False)\r\n",
        "            x = keras.layers.add([x, y])\r\n",
        "\r\n",
        "        num_filters_in = num_filters_out\r\n",
        "\r\n",
        "    # Add classifier on top.\r\n",
        "    # v2 has BN-ReLU before Pooling\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = AveragePooling2D(pool_size=8)(x)\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,activation='softmax',kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    # Instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "if version == 2:\r\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\r\n",
        "else:\r\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=Adam(learning_rate=lr_schedule(0)),\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "print(model_type)\r\n",
        "\r\n",
        "# Prepare model model saving directory.\r\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\r\n",
        "if not os.path.isdir(save_dir):\r\n",
        "    os.makedirs(save_dir)\r\n",
        "filepath = os.path.join(save_dir, model_name)\r\n",
        "\r\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\r\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\r\n",
        "                             monitor='val_acc',\r\n",
        "                             verbose=1,\r\n",
        "                             save_best_only=True)\r\n",
        "\r\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\r\n",
        "\r\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n",
        "                               cooldown=0,\r\n",
        "                               patience=5,\r\n",
        "                               min_lr=0.5e-6)\r\n",
        "\r\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\r\n",
        "\r\n",
        "# Run training, with or without data augmentation.\r\n",
        "if not data_augmentation:\r\n",
        "    print('Not using data augmentation.')\r\n",
        "    model.fit(x_train, y_train,\r\n",
        "              batch_size=batch_size,\r\n",
        "              epochs=epochs,\r\n",
        "              validation_data=(x_test, y_test),\r\n",
        "              shuffle=True,\r\n",
        "              callbacks=callbacks)\r\n",
        "else:\r\n",
        "    print('Using real-time data augmentation.')\r\n",
        "    # This will do preprocessing and realtime data augmentation:\r\n",
        "    datagen = ImageDataGenerator(\r\n",
        "        # set input mean to 0 over the dataset\r\n",
        "        featurewise_center=False,\r\n",
        "        # set each sample mean to 0\r\n",
        "        samplewise_center=False,\r\n",
        "        # divide inputs by std of dataset\r\n",
        "        featurewise_std_normalization=False,\r\n",
        "        # divide each input by its std\r\n",
        "        samplewise_std_normalization=False,\r\n",
        "        # apply ZCA whitening\r\n",
        "        zca_whitening=False,\r\n",
        "        # epsilon for ZCA whitening\r\n",
        "        zca_epsilon=1e-06,\r\n",
        "        # randomly rotate images in the range (deg 0 to 180)\r\n",
        "        rotation_range=0,\r\n",
        "        # randomly shift images horizontally\r\n",
        "        width_shift_range=0.1,\r\n",
        "        # randomly shift images vertically\r\n",
        "        height_shift_range=0.1,\r\n",
        "        # set range for random shear\r\n",
        "        shear_range=0.,\r\n",
        "        # set range for random zoom\r\n",
        "        zoom_range=0.,\r\n",
        "        # set range for random channel shifts\r\n",
        "        channel_shift_range=0.,\r\n",
        "        # set mode for filling points outside the input boundaries\r\n",
        "        fill_mode='nearest',\r\n",
        "        # value used for fill_mode = \"constant\"\r\n",
        "        cval=0.,\r\n",
        "        # randomly flip images\r\n",
        "        horizontal_flip=True,\r\n",
        "        # randomly flip images\r\n",
        "        vertical_flip=False,\r\n",
        "        # set rescaling factor (applied before any other transformation)\r\n",
        "        rescale=None,\r\n",
        "        # set function that will be applied on each input\r\n",
        "        preprocessing_function=None,\r\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\r\n",
        "        data_format=None,\r\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\r\n",
        "        validation_split=0.0)\r\n",
        "\r\n",
        "    # Compute quantities required for featurewise normalization\r\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\r\n",
        "    datagen.fit(x_train)\r\n",
        "\r\n",
        "    # Fit the model on the batches generated by datagen.flow().\r\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\r\n",
        "                        validation_data=(x_test, y_test),\r\n",
        "                        epochs=epochs, verbose=1, workers=4,\r\n",
        "                        callbacks=callbacks)\r\n",
        "\r\n",
        "# Score trained model.\r\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\r\n",
        "print('Test loss:', scores[0])\r\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n",
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 16)   0           activation_15[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_17[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_19[0][0]              \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 32)   4640        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 32)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 32)   544         activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 32)   0           conv2d_22[0][0]                  \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 32)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           activation_23[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           activation_25[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 64)     18496       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 64)     36928       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 64)     2112        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 64)     0           conv2d_29[0][0]                  \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 64)     36928       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 64)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           activation_29[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 64)     36928       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 64)     0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 64)     36928       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 64)     256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           activation_31[0][0]              \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n",
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 40s 24ms/step - loss: 1.8203 - accuracy: 0.4008 - val_loss: 1.5367 - val_accuracy: 0.5089\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.2117 - accuracy: 0.6277 - val_loss: 1.4921 - val_accuracy: 0.5508\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 1.0394 - accuracy: 0.6940 - val_loss: 1.1411 - val_accuracy: 0.6648\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9346 - accuracy: 0.7338 - val_loss: 1.2577 - val_accuracy: 0.6639\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8732 - accuracy: 0.7543 - val_loss: 1.0954 - val_accuracy: 0.7012\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8257 - accuracy: 0.7717 - val_loss: 0.8668 - val_accuracy: 0.7609\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7812 - accuracy: 0.7902 - val_loss: 0.8320 - val_accuracy: 0.7763\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7584 - accuracy: 0.7981 - val_loss: 1.0338 - val_accuracy: 0.7208\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7359 - accuracy: 0.8067 - val_loss: 0.8708 - val_accuracy: 0.7717\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7115 - accuracy: 0.8175 - val_loss: 0.8274 - val_accuracy: 0.7907\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.6879 - accuracy: 0.8267 - val_loss: 0.8389 - val_accuracy: 0.7805\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6756 - accuracy: 0.8331 - val_loss: 0.7368 - val_accuracy: 0.8133\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6678 - accuracy: 0.8345 - val_loss: 0.8369 - val_accuracy: 0.7884\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6550 - accuracy: 0.8384 - val_loss: 0.8360 - val_accuracy: 0.7958\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6501 - accuracy: 0.8414 - val_loss: 0.7692 - val_accuracy: 0.8049\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6315 - accuracy: 0.8468 - val_loss: 0.8633 - val_accuracy: 0.7804\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6217 - accuracy: 0.8501 - val_loss: 0.7856 - val_accuracy: 0.8055\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6208 - accuracy: 0.8514 - val_loss: 0.7823 - val_accuracy: 0.8041\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6051 - accuracy: 0.8576 - val_loss: 0.8016 - val_accuracy: 0.8037\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6128 - accuracy: 0.8556 - val_loss: 0.9050 - val_accuracy: 0.7880\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 21/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5923 - accuracy: 0.8634 - val_loss: 0.7468 - val_accuracy: 0.8151\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 22/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5931 - accuracy: 0.8653 - val_loss: 0.6853 - val_accuracy: 0.8325\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 23/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5843 - accuracy: 0.8665 - val_loss: 0.9729 - val_accuracy: 0.7645\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 24/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5847 - accuracy: 0.8680 - val_loss: 0.8941 - val_accuracy: 0.7831\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 25/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5737 - accuracy: 0.8715 - val_loss: 0.7186 - val_accuracy: 0.8293\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 26/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5652 - accuracy: 0.8749 - val_loss: 0.6954 - val_accuracy: 0.8332\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 27/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5736 - accuracy: 0.8710 - val_loss: 0.7656 - val_accuracy: 0.8163\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 28/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5706 - accuracy: 0.8724 - val_loss: 0.8063 - val_accuracy: 0.8009\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 29/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5651 - accuracy: 0.8744 - val_loss: 0.7113 - val_accuracy: 0.8293\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 30/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5587 - accuracy: 0.8786 - val_loss: 0.8670 - val_accuracy: 0.7986\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 31/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5548 - accuracy: 0.8764 - val_loss: 0.7274 - val_accuracy: 0.8321\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 32/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5458 - accuracy: 0.8832 - val_loss: 0.7125 - val_accuracy: 0.8337\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 33/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5531 - accuracy: 0.8792 - val_loss: 0.7873 - val_accuracy: 0.8155\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 34/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5478 - accuracy: 0.8810 - val_loss: 0.7189 - val_accuracy: 0.8322\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 35/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5472 - accuracy: 0.8824 - val_loss: 0.7852 - val_accuracy: 0.8219\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 36/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5413 - accuracy: 0.8823 - val_loss: 0.6427 - val_accuracy: 0.8568\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 37/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5288 - accuracy: 0.8884 - val_loss: 0.7743 - val_accuracy: 0.8132\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 38/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5416 - accuracy: 0.8837 - val_loss: 0.7650 - val_accuracy: 0.8264\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 39/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5372 - accuracy: 0.8835 - val_loss: 0.7968 - val_accuracy: 0.8196\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 40/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5344 - accuracy: 0.8866 - val_loss: 0.8079 - val_accuracy: 0.8199\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 41/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5346 - accuracy: 0.8857 - val_loss: 0.6800 - val_accuracy: 0.8485\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 42/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5269 - accuracy: 0.8898 - val_loss: 0.6793 - val_accuracy: 0.8453\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 43/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5223 - accuracy: 0.8900 - val_loss: 0.6385 - val_accuracy: 0.8552\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 44/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5145 - accuracy: 0.8946 - val_loss: 0.7310 - val_accuracy: 0.8258\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 45/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5180 - accuracy: 0.8922 - val_loss: 0.7367 - val_accuracy: 0.8342\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 46/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.5248 - accuracy: 0.8897 - val_loss: 0.7498 - val_accuracy: 0.8277\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 47/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5231 - accuracy: 0.8904 - val_loss: 0.6390 - val_accuracy: 0.8527\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 48/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5131 - accuracy: 0.8930 - val_loss: 0.7352 - val_accuracy: 0.8271\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 49/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5143 - accuracy: 0.8949 - val_loss: 0.8744 - val_accuracy: 0.8032\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 50/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5159 - accuracy: 0.8926 - val_loss: 0.8311 - val_accuracy: 0.8092\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 51/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5111 - accuracy: 0.8950 - val_loss: 0.7151 - val_accuracy: 0.8431\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 52/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5069 - accuracy: 0.8963 - val_loss: 0.7000 - val_accuracy: 0.8416\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 53/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5079 - accuracy: 0.8969 - val_loss: 0.6764 - val_accuracy: 0.8469\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 54/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.5054 - accuracy: 0.8966 - val_loss: 0.6687 - val_accuracy: 0.8523\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 55/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5064 - accuracy: 0.8960 - val_loss: 0.6207 - val_accuracy: 0.8629\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 56/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.4964 - accuracy: 0.8994 - val_loss: 0.6577 - val_accuracy: 0.8527\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 57/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5031 - accuracy: 0.8985 - val_loss: 0.6204 - val_accuracy: 0.8631\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 58/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4982 - accuracy: 0.8979 - val_loss: 0.6363 - val_accuracy: 0.8578\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 59/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5021 - accuracy: 0.8971 - val_loss: 0.6164 - val_accuracy: 0.8664\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 60/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5005 - accuracy: 0.8969 - val_loss: 0.6408 - val_accuracy: 0.8508\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 61/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4938 - accuracy: 0.9005 - val_loss: 0.8855 - val_accuracy: 0.7953\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 62/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4879 - accuracy: 0.9016 - val_loss: 0.7854 - val_accuracy: 0.8232\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 63/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.4981 - accuracy: 0.8997 - val_loss: 0.7605 - val_accuracy: 0.8248\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 64/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5007 - accuracy: 0.8990 - val_loss: 0.7176 - val_accuracy: 0.8326\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 65/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.4930 - accuracy: 0.9008 - val_loss: 0.7724 - val_accuracy: 0.8259\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 66/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4999 - accuracy: 0.9001 - val_loss: 0.9147 - val_accuracy: 0.7974\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 67/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4978 - accuracy: 0.8988 - val_loss: 0.7105 - val_accuracy: 0.8314\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 68/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4943 - accuracy: 0.9006 - val_loss: 0.6103 - val_accuracy: 0.8598\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 69/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4817 - accuracy: 0.9037 - val_loss: 0.6047 - val_accuracy: 0.8702\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 70/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4879 - accuracy: 0.9038 - val_loss: 0.7230 - val_accuracy: 0.8334\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 71/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4877 - accuracy: 0.9039 - val_loss: 0.7498 - val_accuracy: 0.8321\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 72/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4801 - accuracy: 0.9047 - val_loss: 0.6293 - val_accuracy: 0.8589\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 73/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.4895 - accuracy: 0.9013 - val_loss: 0.6891 - val_accuracy: 0.8435\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 74/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4840 - accuracy: 0.9046 - val_loss: 0.7097 - val_accuracy: 0.8414\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 75/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4871 - accuracy: 0.9030 - val_loss: 0.7373 - val_accuracy: 0.8357\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 76/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4792 - accuracy: 0.9040 - val_loss: 0.6827 - val_accuracy: 0.8461\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 77/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4773 - accuracy: 0.9073 - val_loss: 0.6518 - val_accuracy: 0.8632\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 78/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4755 - accuracy: 0.9079 - val_loss: 0.8335 - val_accuracy: 0.8073\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 79/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4838 - accuracy: 0.9034 - val_loss: 0.6539 - val_accuracy: 0.8559\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 80/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4839 - accuracy: 0.9044 - val_loss: 0.6759 - val_accuracy: 0.8515\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 81/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.4799 - accuracy: 0.9046 - val_loss: 0.6863 - val_accuracy: 0.8466\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 82/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4295 - accuracy: 0.9234 - val_loss: 0.4942 - val_accuracy: 0.9001\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 83/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3777 - accuracy: 0.9404 - val_loss: 0.4886 - val_accuracy: 0.9039\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 84/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3626 - accuracy: 0.9438 - val_loss: 0.4860 - val_accuracy: 0.9056\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 85/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3454 - accuracy: 0.9487 - val_loss: 0.4752 - val_accuracy: 0.9081\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 86/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3417 - accuracy: 0.9482 - val_loss: 0.4759 - val_accuracy: 0.9077\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 87/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3294 - accuracy: 0.9510 - val_loss: 0.4813 - val_accuracy: 0.9064\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 88/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3171 - accuracy: 0.9546 - val_loss: 0.4722 - val_accuracy: 0.9088\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 89/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3150 - accuracy: 0.9551 - val_loss: 0.4654 - val_accuracy: 0.9095\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 90/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3075 - accuracy: 0.9555 - val_loss: 0.4597 - val_accuracy: 0.9118\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 91/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.3007 - accuracy: 0.9570 - val_loss: 0.4656 - val_accuracy: 0.9096\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 92/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.2934 - accuracy: 0.9575 - val_loss: 0.4555 - val_accuracy: 0.9125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 93/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.2925 - accuracy: 0.9572 - val_loss: 0.4501 - val_accuracy: 0.9127\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 94/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.2878 - accuracy: 0.9587 - val_loss: 0.4847 - val_accuracy: 0.9028\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 95/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.2790 - accuracy: 0.9618 - val_loss: 0.4464 - val_accuracy: 0.9124\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 96/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.2766 - accuracy: 0.9597 - val_loss: 0.4445 - val_accuracy: 0.9121\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 97/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.2675 - accuracy: 0.9643 - val_loss: 0.4483 - val_accuracy: 0.9130\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 98/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2674 - accuracy: 0.9628 - val_loss: 0.4370 - val_accuracy: 0.9154\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 99/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.2626 - accuracy: 0.9646 - val_loss: 0.4501 - val_accuracy: 0.9107\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 100/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 35s 23ms/step - loss: 0.2617 - accuracy: 0.9629 - val_loss: 0.4378 - val_accuracy: 0.9130\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 101/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.2550 - accuracy: 0.9644 - val_loss: 0.4568 - val_accuracy: 0.9091\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 102/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.2554 - accuracy: 0.9637 - val_loss: 0.4408 - val_accuracy: 0.9130\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 103/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.2549 - accuracy: 0.9641 - val_loss: 0.4502 - val_accuracy: 0.9107\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 104/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.2450 - accuracy: 0.9677 - val_loss: 0.4430 - val_accuracy: 0.9119\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 105/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.2419 - accuracy: 0.9678 - val_loss: 0.4485 - val_accuracy: 0.9114\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 106/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.2378 - accuracy: 0.9696 - val_loss: 0.4637 - val_accuracy: 0.9078\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 107/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2391 - accuracy: 0.9676 - val_loss: 0.4527 - val_accuracy: 0.9113\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 108/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.2348 - accuracy: 0.9685 - val_loss: 0.4522 - val_accuracy: 0.9074\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 109/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2289 - accuracy: 0.9708 - val_loss: 0.4453 - val_accuracy: 0.9113\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 110/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2279 - accuracy: 0.9705 - val_loss: 0.4556 - val_accuracy: 0.9060\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 111/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.2264 - accuracy: 0.9712 - val_loss: 0.4539 - val_accuracy: 0.9094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 112/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.2236 - accuracy: 0.9710 - val_loss: 0.4458 - val_accuracy: 0.9106\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 113/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2203 - accuracy: 0.9725 - val_loss: 0.4402 - val_accuracy: 0.9138\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 114/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.2172 - accuracy: 0.9709 - val_loss: 0.4472 - val_accuracy: 0.9112\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 115/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2173 - accuracy: 0.9714 - val_loss: 0.4503 - val_accuracy: 0.9109\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 116/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2091 - accuracy: 0.9734 - val_loss: 0.4484 - val_accuracy: 0.9100\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 117/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2141 - accuracy: 0.9724 - val_loss: 0.4504 - val_accuracy: 0.9105\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 118/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2106 - accuracy: 0.9733 - val_loss: 0.4321 - val_accuracy: 0.9144\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 119/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2053 - accuracy: 0.9750 - val_loss: 0.4449 - val_accuracy: 0.9110\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 120/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2072 - accuracy: 0.9734 - val_loss: 0.4430 - val_accuracy: 0.9108\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 121/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2057 - accuracy: 0.9734 - val_loss: 0.4538 - val_accuracy: 0.9098\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 122/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1984 - accuracy: 0.9758 - val_loss: 0.4381 - val_accuracy: 0.9143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 123/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1941 - accuracy: 0.9784 - val_loss: 0.4318 - val_accuracy: 0.9150\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 124/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1913 - accuracy: 0.9791 - val_loss: 0.4343 - val_accuracy: 0.9140\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 125/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1906 - accuracy: 0.9797 - val_loss: 0.4315 - val_accuracy: 0.9151\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 126/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1897 - accuracy: 0.9801 - val_loss: 0.4322 - val_accuracy: 0.9150\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 127/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1881 - accuracy: 0.9802 - val_loss: 0.4299 - val_accuracy: 0.9149\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 128/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1868 - accuracy: 0.9793 - val_loss: 0.4309 - val_accuracy: 0.9140\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 129/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1863 - accuracy: 0.9809 - val_loss: 0.4329 - val_accuracy: 0.9142\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 130/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1863 - accuracy: 0.9801 - val_loss: 0.4330 - val_accuracy: 0.9133\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 131/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1849 - accuracy: 0.9798 - val_loss: 0.4293 - val_accuracy: 0.9142\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 132/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1839 - accuracy: 0.9808 - val_loss: 0.4296 - val_accuracy: 0.9153\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 133/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1818 - accuracy: 0.9818 - val_loss: 0.4316 - val_accuracy: 0.9148\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 134/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1843 - accuracy: 0.9812 - val_loss: 0.4295 - val_accuracy: 0.9145\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 135/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1819 - accuracy: 0.9819 - val_loss: 0.4315 - val_accuracy: 0.9147\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 136/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1837 - accuracy: 0.9806 - val_loss: 0.4294 - val_accuracy: 0.9152\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 137/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1821 - accuracy: 0.9812 - val_loss: 0.4305 - val_accuracy: 0.9152\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 138/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1804 - accuracy: 0.9821 - val_loss: 0.4324 - val_accuracy: 0.9159\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 139/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1823 - accuracy: 0.9811 - val_loss: 0.4316 - val_accuracy: 0.9151\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 140/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.1808 - accuracy: 0.9817 - val_loss: 0.4320 - val_accuracy: 0.9160\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 141/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.1793 - accuracy: 0.9815 - val_loss: 0.4325 - val_accuracy: 0.9159\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 142/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.1808 - accuracy: 0.9822 - val_loss: 0.4301 - val_accuracy: 0.9159\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 143/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.1796 - accuracy: 0.9825 - val_loss: 0.4300 - val_accuracy: 0.9155\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 144/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.1784 - accuracy: 0.9824 - val_loss: 0.4309 - val_accuracy: 0.9159\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 145/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1762 - accuracy: 0.9842 - val_loss: 0.4317 - val_accuracy: 0.9155\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 146/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1769 - accuracy: 0.9831 - val_loss: 0.4323 - val_accuracy: 0.9160\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 147/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1748 - accuracy: 0.9833 - val_loss: 0.4343 - val_accuracy: 0.9156\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 148/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1769 - accuracy: 0.9832 - val_loss: 0.4320 - val_accuracy: 0.9151\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 149/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1770 - accuracy: 0.9826 - val_loss: 0.4295 - val_accuracy: 0.9150\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 150/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1780 - accuracy: 0.9822 - val_loss: 0.4352 - val_accuracy: 0.9145\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 151/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1784 - accuracy: 0.9821 - val_loss: 0.4338 - val_accuracy: 0.9141\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 152/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1788 - accuracy: 0.9817 - val_loss: 0.4349 - val_accuracy: 0.9135\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 153/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1750 - accuracy: 0.9831 - val_loss: 0.4346 - val_accuracy: 0.9153\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 154/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1743 - accuracy: 0.9826 - val_loss: 0.4346 - val_accuracy: 0.9147\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 155/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1753 - accuracy: 0.9822 - val_loss: 0.4345 - val_accuracy: 0.9139\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 156/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1738 - accuracy: 0.9838 - val_loss: 0.4358 - val_accuracy: 0.9142\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 157/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1711 - accuracy: 0.9849 - val_loss: 0.4331 - val_accuracy: 0.9149\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 158/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1727 - accuracy: 0.9836 - val_loss: 0.4333 - val_accuracy: 0.9145\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 159/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1724 - accuracy: 0.9834 - val_loss: 0.4350 - val_accuracy: 0.9149\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 160/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1744 - accuracy: 0.9823 - val_loss: 0.4355 - val_accuracy: 0.9140\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 161/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1714 - accuracy: 0.9849 - val_loss: 0.4332 - val_accuracy: 0.9154\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 162/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1710 - accuracy: 0.9839 - val_loss: 0.4337 - val_accuracy: 0.9147\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 163/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.1725 - accuracy: 0.9836 - val_loss: 0.4343 - val_accuracy: 0.9139\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 164/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1742 - accuracy: 0.9828 - val_loss: 0.4326 - val_accuracy: 0.9155\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 165/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1719 - accuracy: 0.9838 - val_loss: 0.4327 - val_accuracy: 0.9158\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 166/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.1709 - accuracy: 0.9840 - val_loss: 0.4341 - val_accuracy: 0.9153\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 167/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1719 - accuracy: 0.9838 - val_loss: 0.4326 - val_accuracy: 0.9152\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 168/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1727 - accuracy: 0.9838 - val_loss: 0.4344 - val_accuracy: 0.9147\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 169/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1753 - accuracy: 0.9828 - val_loss: 0.4346 - val_accuracy: 0.9152\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 170/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1710 - accuracy: 0.9840 - val_loss: 0.4324 - val_accuracy: 0.9154\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 171/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1719 - accuracy: 0.9836 - val_loss: 0.4349 - val_accuracy: 0.9154\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 172/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1727 - accuracy: 0.9831 - val_loss: 0.4344 - val_accuracy: 0.9150\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 173/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1722 - accuracy: 0.9837 - val_loss: 0.4332 - val_accuracy: 0.9146\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 174/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1714 - accuracy: 0.9844 - val_loss: 0.4343 - val_accuracy: 0.9143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 175/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1709 - accuracy: 0.9843 - val_loss: 0.4321 - val_accuracy: 0.9150\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 176/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1740 - accuracy: 0.9833 - val_loss: 0.4341 - val_accuracy: 0.9150\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 177/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1719 - accuracy: 0.9840 - val_loss: 0.4334 - val_accuracy: 0.9144\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 178/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1715 - accuracy: 0.9832 - val_loss: 0.4339 - val_accuracy: 0.9148\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 179/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1689 - accuracy: 0.9846 - val_loss: 0.4345 - val_accuracy: 0.9147\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 180/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1715 - accuracy: 0.9836 - val_loss: 0.4338 - val_accuracy: 0.9149\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 181/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1729 - accuracy: 0.9827 - val_loss: 0.4345 - val_accuracy: 0.9148\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 182/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1718 - accuracy: 0.9836 - val_loss: 0.4329 - val_accuracy: 0.9144\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 183/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1750 - accuracy: 0.9821 - val_loss: 0.4327 - val_accuracy: 0.9157\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 184/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1733 - accuracy: 0.9832 - val_loss: 0.4318 - val_accuracy: 0.9152\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 185/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1714 - accuracy: 0.9844 - val_loss: 0.4318 - val_accuracy: 0.9153\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 186/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1698 - accuracy: 0.9853 - val_loss: 0.4337 - val_accuracy: 0.9146\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 187/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1712 - accuracy: 0.9842 - val_loss: 0.4331 - val_accuracy: 0.9142\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 188/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1736 - accuracy: 0.9829 - val_loss: 0.4320 - val_accuracy: 0.9148\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 189/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.1714 - accuracy: 0.9841 - val_loss: 0.4341 - val_accuracy: 0.9146\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 190/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.1707 - accuracy: 0.9839 - val_loss: 0.4344 - val_accuracy: 0.9147\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 191/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1716 - accuracy: 0.9839 - val_loss: 0.4341 - val_accuracy: 0.9149\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 192/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1703 - accuracy: 0.9852 - val_loss: 0.4319 - val_accuracy: 0.9146\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 193/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1722 - accuracy: 0.9838 - val_loss: 0.4346 - val_accuracy: 0.9139\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 194/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.1702 - accuracy: 0.9844 - val_loss: 0.4312 - val_accuracy: 0.9158\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 195/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1708 - accuracy: 0.9844 - val_loss: 0.4339 - val_accuracy: 0.9150\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 196/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.1690 - accuracy: 0.9852 - val_loss: 0.4333 - val_accuracy: 0.9150\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 197/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.1728 - accuracy: 0.9830 - val_loss: 0.4343 - val_accuracy: 0.9142\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 198/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.1730 - accuracy: 0.9830 - val_loss: 0.4334 - val_accuracy: 0.9148\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 199/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.1723 - accuracy: 0.9829 - val_loss: 0.4339 - val_accuracy: 0.9141\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 200/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1701 - accuracy: 0.9832 - val_loss: 0.4345 - val_accuracy: 0.9144\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4345 - accuracy: 0.9144\n",
            "Test loss: 0.43454623222351074\n",
            "Test accuracy: 0.9143999814987183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xq3bLBziL1V"
      },
      "source": [
        "resnet v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOs2fSvKiOIy",
        "outputId": "ad4cd53c-cb85-447c-db97-5e2980ad5b46"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import keras\r\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation,AveragePooling2D, Input, Flatten\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras import backend as K\r\n",
        "from keras.models import Model\r\n",
        "from keras.datasets import cifar10\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "#設置參數\r\n",
        "batch_size = 32\r\n",
        "epochs = 200\r\n",
        "data_augmentation = True #數據增強\r\n",
        "num_classes = 10\r\n",
        "subtract_pixel_mean = True# Subtracting pixel mean improves accuracy(減去像素均值可提高準確性)\r\n",
        "n=3 # Model parameter\r\n",
        "\r\n",
        "# Model version\r\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\r\n",
        "version = 2\r\n",
        "\r\n",
        "#根據前面設的模型參數n來計算深度\r\n",
        "if version == 1:\r\n",
        "    depth = n * 6 + 2\r\n",
        "elif version == 2:\r\n",
        "    depth = n * 9 + 2\r\n",
        "\r\n",
        "# Model name, depth and version\r\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\r\n",
        "\r\n",
        "# Loading data\r\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n",
        "\r\n",
        "# Input image dimensions.\r\n",
        "input_shape = x_train.shape[1:]\r\n",
        "\r\n",
        "# Normalize data.\r\n",
        "x_train = x_train.astype('float32') / 255\r\n",
        "x_test = x_test.astype('float32') / 255\r\n",
        "\r\n",
        "# 如果啟用減法像素均值(subtract pixel mean)\r\n",
        "if subtract_pixel_mean:\r\n",
        "    x_train_mean = np.mean(x_train, axis=0)\r\n",
        "    x_train -= x_train_mean\r\n",
        "    x_test -= x_train_mean\r\n",
        "\r\n",
        "print('x_train shape:', x_train.shape)\r\n",
        "print(x_train.shape[0], 'train samples')\r\n",
        "print(x_test.shape[0], 'test samples')\r\n",
        "print('y_train shape:', y_train.shape)\r\n",
        "\r\n",
        "# Convert class vectors to binary class matrices.\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "\r\n",
        "def lr_schedule(epoch):\r\n",
        "#Learning Rate Schedule\r\n",
        "#預計在80,120,160,180 epochs後降低learning rate.\r\n",
        "#在訓練過程中，作為回調(callbacks)的一部份，自動調用每個epoch\r\n",
        "# 參數- epoch (int): The number of epochs\r\n",
        "# Returns- lr (float32): learning rate\r\n",
        "    lr = 1e-3\r\n",
        "    if epoch > 180:\r\n",
        "        lr *= 0.5e-3\r\n",
        "    elif epoch > 160:\r\n",
        "        lr *= 1e-3\r\n",
        "    elif epoch > 120:\r\n",
        "        lr *= 1e-2\r\n",
        "    elif epoch > 80:\r\n",
        "        lr *= 1e-1\r\n",
        "    print('Learning rate: ', lr)\r\n",
        "    return lr\r\n",
        "\r\n",
        "def resnet_layer(inputs,\r\n",
        "                 num_filters=16,\r\n",
        "                 kernel_size=3,\r\n",
        "                 strides=1,\r\n",
        "                 activation='relu',\r\n",
        "                 batch_normalization=True,\r\n",
        "                 conv_first=True):\r\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        inputs (tensor): input tensor from input image or previous layer\r\n",
        "        num_filters (int): Conv2D number of filters\r\n",
        "        kernel_size (int): Conv2D square kernel dimensions\r\n",
        "        strides (int): Conv2D square stride dimensions\r\n",
        "        activation (string): activation name\r\n",
        "        batch_normalization (bool): whether to include batch normalization\r\n",
        "        conv_first (bool): conv-bn-activation (True) or\r\n",
        "            bn-activation-conv (False)\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        x (tensor): tensor as input to the next layer\r\n",
        "    \"\"\"\r\n",
        "    conv = Conv2D(num_filters,\r\n",
        "                  kernel_size=kernel_size,\r\n",
        "                  strides=strides,\r\n",
        "                  padding='same',\r\n",
        "                  kernel_initializer='he_normal',\r\n",
        "                  kernel_regularizer=l2(1e-4))\r\n",
        "\r\n",
        "    x = inputs\r\n",
        "    if conv_first:\r\n",
        "        x = conv(x)\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "    else:\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "        x = conv(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\r\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\r\n",
        "\r\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n",
        "    Last ReLU is after the shortcut connection.\r\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\r\n",
        "    by a convolutional layer with strides=2, while the number of filters is\r\n",
        "    doubled. Within each stage, the layers have the same number filters and the\r\n",
        "    same number of filters.\r\n",
        "    Features maps sizes:\r\n",
        "    stage 0: 32x32, 16\r\n",
        "    stage 1: 16x16, 32\r\n",
        "    stage 2:  8x8,  64\r\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\r\n",
        "    ResNet20 0.27M\r\n",
        "    ResNet32 0.46M\r\n",
        "    ResNet44 0.66M\r\n",
        "    ResNet56 0.85M\r\n",
        "    ResNet110 1.7M\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        input_shape (tensor): shape of input image tensor\r\n",
        "        depth (int): number of core convolutional layers\r\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        model (Model): Keras model instance\r\n",
        "    \"\"\"\r\n",
        "    if (depth - 2) % 6 != 0:\r\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n",
        "    # Start model definition.\r\n",
        "    num_filters = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 6)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    x = resnet_layer(inputs=inputs)\r\n",
        "    # Instantiate the stack of residual units\r\n",
        "    for stack in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            strides = 1\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                strides = 2  # downsample\r\n",
        "            y = resnet_layer(inputs=x,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             strides=strides)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             activation=None)\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                # linear projection residual shortcut connection to match\r\n",
        "                # changed dims\r\n",
        "                x = resnet_layer(inputs=x,\r\n",
        "                                 num_filters=num_filters,\r\n",
        "                                 kernel_size=1,\r\n",
        "                                 strides=strides,\r\n",
        "                                 activation=None,\r\n",
        "                                 batch_normalization=False)\r\n",
        "            x = keras.layers.add([x, y])\r\n",
        "            x = Activation('relu')(x)\r\n",
        "        num_filters *= 2\r\n",
        "\r\n",
        "    # Add classifier on top.\r\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\r\n",
        "    x = AveragePooling2D(pool_size=8)(x)\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,\r\n",
        "                    activation='softmax',\r\n",
        "                    kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    # Instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\r\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\r\n",
        "\r\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\r\n",
        "    bottleneck layer\r\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\r\n",
        "    Second and onwards shortcut connection is identity.\r\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\r\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\r\n",
        "    doubled. Within each stage, the layers have the same number filters and the\r\n",
        "    same filter map sizes.\r\n",
        "    Features maps sizes:\r\n",
        "    conv1  : 32x32,  16\r\n",
        "    stage 0: 32x32,  64\r\n",
        "    stage 1: 16x16, 128\r\n",
        "    stage 2:  8x8,  256\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        input_shape (tensor): shape of input image tensor\r\n",
        "        depth (int): number of core convolutional layers\r\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        model (Model): Keras model instance\r\n",
        "    \"\"\"\r\n",
        "    if (depth - 2) % 9 != 0:\r\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\r\n",
        "    # Start model definition.\r\n",
        "    num_filters_in = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 9)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\r\n",
        "    x = resnet_layer(inputs=inputs,\r\n",
        "                     num_filters=num_filters_in,\r\n",
        "                     conv_first=True)\r\n",
        "\r\n",
        "    # Instantiate the stack of residual units\r\n",
        "    for stage in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            activation = 'relu'\r\n",
        "            batch_normalization = True\r\n",
        "            strides = 1\r\n",
        "            if stage == 0:\r\n",
        "                num_filters_out = num_filters_in * 4\r\n",
        "                if res_block == 0:  # first layer and first stage\r\n",
        "                    activation = None\r\n",
        "                    batch_normalization = False\r\n",
        "            else:\r\n",
        "                num_filters_out = num_filters_in * 2\r\n",
        "                if res_block == 0:  # first layer but not first stage\r\n",
        "                    strides = 2    # downsample\r\n",
        "\r\n",
        "            # bottleneck residual unit\r\n",
        "            y = resnet_layer(inputs=x,\r\n",
        "                             num_filters=num_filters_in,\r\n",
        "                             kernel_size=1,\r\n",
        "                             strides=strides,\r\n",
        "                             activation=activation,\r\n",
        "                             batch_normalization=batch_normalization,\r\n",
        "                             conv_first=False)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters_in,\r\n",
        "                             conv_first=False)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters_out,\r\n",
        "                             kernel_size=1,\r\n",
        "                             conv_first=False)\r\n",
        "            if res_block == 0:\r\n",
        "                # linear projection residual shortcut connection to match\r\n",
        "                # changed dims\r\n",
        "                x = resnet_layer(inputs=x,\r\n",
        "                                 num_filters=num_filters_out,\r\n",
        "                                 kernel_size=1,\r\n",
        "                                 strides=strides,\r\n",
        "                                 activation=None,\r\n",
        "                                 batch_normalization=False)\r\n",
        "            x = keras.layers.add([x, y])\r\n",
        "\r\n",
        "        num_filters_in = num_filters_out\r\n",
        "\r\n",
        "    # Add classifier on top.\r\n",
        "    # v2 has BN-ReLU before Pooling\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = AveragePooling2D(pool_size=8)(x)\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,\r\n",
        "                    activation='softmax',\r\n",
        "                    kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    # Instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "if version == 2:\r\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\r\n",
        "else:\r\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=Adam(learning_rate=lr_schedule(0)),\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "print(model_type)\r\n",
        "\r\n",
        "# Prepare model model saving directory.\r\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\r\n",
        "if not os.path.isdir(save_dir):\r\n",
        "    os.makedirs(save_dir)\r\n",
        "filepath = os.path.join(save_dir, model_name)\r\n",
        "\r\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\r\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\r\n",
        "                             monitor='val_acc',\r\n",
        "                             verbose=1,\r\n",
        "                             save_best_only=True)\r\n",
        "\r\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\r\n",
        "\r\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n",
        "                               cooldown=0,\r\n",
        "                               patience=5,\r\n",
        "                               min_lr=0.5e-6)\r\n",
        "\r\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\r\n",
        "\r\n",
        "# Run training, with or without data augmentation.\r\n",
        "if not data_augmentation:\r\n",
        "    print('Not using data augmentation.')\r\n",
        "    model.fit(x_train, y_train,\r\n",
        "              batch_size=batch_size,\r\n",
        "              epochs=epochs,\r\n",
        "              validation_data=(x_test, y_test),\r\n",
        "              shuffle=True,\r\n",
        "              callbacks=callbacks)\r\n",
        "else:\r\n",
        "    print('Using real-time data augmentation.')\r\n",
        "    # This will do preprocessing and realtime data augmentation:\r\n",
        "    datagen = ImageDataGenerator(\r\n",
        "        # set input mean to 0 over the dataset\r\n",
        "        featurewise_center=False,\r\n",
        "        # set each sample mean to 0\r\n",
        "        samplewise_center=False,\r\n",
        "        # divide inputs by std of dataset\r\n",
        "        featurewise_std_normalization=False,\r\n",
        "        # divide each input by its std\r\n",
        "        samplewise_std_normalization=False,\r\n",
        "        # apply ZCA whitening\r\n",
        "        zca_whitening=False,\r\n",
        "        # epsilon for ZCA whitening\r\n",
        "        zca_epsilon=1e-06,\r\n",
        "        # randomly rotate images in the range (deg 0 to 180)\r\n",
        "        rotation_range=0,\r\n",
        "        # randomly shift images horizontally\r\n",
        "        width_shift_range=0.1,\r\n",
        "        # randomly shift images vertically\r\n",
        "        height_shift_range=0.1,\r\n",
        "        # set range for random shear\r\n",
        "        shear_range=0.,\r\n",
        "        # set range for random zoom\r\n",
        "        zoom_range=0.,\r\n",
        "        # set range for random channel shifts\r\n",
        "        channel_shift_range=0.,\r\n",
        "        # set mode for filling points outside the input boundaries\r\n",
        "        fill_mode='nearest',\r\n",
        "        # value used for fill_mode = \"constant\"\r\n",
        "        cval=0.,\r\n",
        "        # randomly flip images\r\n",
        "        horizontal_flip=True,\r\n",
        "        # randomly flip images\r\n",
        "        vertical_flip=False,\r\n",
        "        # set rescaling factor (applied before any other transformation)\r\n",
        "        rescale=None,\r\n",
        "        # set function that will be applied on each input\r\n",
        "        preprocessing_function=None,\r\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\r\n",
        "        data_format=None,\r\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\r\n",
        "        validation_split=0.0)\r\n",
        "\r\n",
        "    # Compute quantities required for featurewise normalization\r\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\r\n",
        "    datagen.fit(x_train)\r\n",
        "\r\n",
        "    # Fit the model on the batches generated by datagen.flow().\r\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\r\n",
        "                        validation_data=(x_test, y_test),\r\n",
        "                        epochs=epochs, verbose=1, workers=4,\r\n",
        "                        callbacks=callbacks)\r\n",
        "\r\n",
        "# Score trained model.\r\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\r\n",
        "print('Test loss:', scores[0])\r\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n",
            "Learning rate:  0.001\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 32, 16)   64          conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 32, 32, 16)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 32, 32, 16)   272         activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 32, 32, 16)   64          conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 32, 32, 16)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 32, 32, 16)   2320        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 32, 32, 16)   64          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 32, 32, 16)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 32, 32, 64)   1088        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 32, 32, 64)   1088        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 32, 32, 64)   0           conv2d_38[0][0]                  \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 32, 32, 64)   256         add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 32, 32, 64)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 32, 32, 16)   1040        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 32, 32, 16)   64          conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 32, 32, 16)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 32, 32, 16)   2320        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 32, 32, 16)   64          conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 32, 32, 16)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 32, 32, 64)   1088        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 64)   0           add_9[0][0]                      \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 32, 32, 64)   256         add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 64)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 16)   1040        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 16)   64          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 16)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 16)   2320        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 16)   64          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 16)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 64)   1088        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 32, 64)   0           add_10[0][0]                     \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 64)   256         add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 64)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 64)   4160        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 64)   256         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 64)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 64)   36928       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 64)   256         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 64)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 128)  8320        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 128)  8320        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 16, 16, 128)  0           conv2d_48[0][0]                  \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 128)  512         add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 128)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 64)   8256        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 64)   256         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 64)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 64)   36928       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 64)   256         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 64)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 128)  8320        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 16, 16, 128)  0           add_12[0][0]                     \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 128)  512         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 128)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 64)   8256        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 64)   256         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 64)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 64)   36928       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 64)   256         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 64)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 128)  8320        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 128)  0           add_13[0][0]                     \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 128)  512         add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 128)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 8, 8, 128)    16512       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 8, 8, 128)    512         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 8, 8, 128)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 8, 8, 128)    147584      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 8, 8, 128)    512         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 8, 8, 128)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 8, 8, 256)    33024       add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 8, 8, 256)    33024       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 256)    0           conv2d_58[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 8, 8, 256)    1024        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 8, 8, 256)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 8, 8, 128)    32896       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 8, 8, 128)    512         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 8, 8, 128)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 8, 8, 128)    147584      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 8, 8, 128)    512         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 8, 8, 128)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 8, 8, 256)    33024       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 256)    0           add_15[0][0]                     \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 8, 8, 256)    1024        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 8, 8, 256)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 8, 8, 128)    32896       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 8, 8, 128)    512         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 8, 8, 128)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 8, 8, 128)    147584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 8, 8, 128)    512         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 8, 8, 128)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 8, 8, 256)    33024       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 256)    0           add_16[0][0]                     \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 8, 8, 256)    1024        add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 8, 8, 256)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 256)          0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           2570        flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 849,002\n",
            "Trainable params: 843,786\n",
            "Non-trainable params: 5,216\n",
            "__________________________________________________________________________________________________\n",
            "ResNet29v2\n",
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 46s 27ms/step - loss: 2.1410 - accuracy: 0.4007 - val_loss: 1.7025 - val_accuracy: 0.5235\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.4361 - accuracy: 0.6027 - val_loss: 1.2945 - val_accuracy: 0.6453\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2130 - accuracy: 0.6736 - val_loss: 1.6770 - val_accuracy: 0.5732\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 1.0840 - accuracy: 0.7187 - val_loss: 1.1853 - val_accuracy: 0.6907\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.9997 - accuracy: 0.7459 - val_loss: 1.2112 - val_accuracy: 0.6834\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.9460 - accuracy: 0.7603 - val_loss: 1.4307 - val_accuracy: 0.6506\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8988 - accuracy: 0.7797 - val_loss: 1.1185 - val_accuracy: 0.7243\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8625 - accuracy: 0.7897 - val_loss: 1.1921 - val_accuracy: 0.6901\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8342 - accuracy: 0.7969 - val_loss: 0.9699 - val_accuracy: 0.7559\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.8047 - accuracy: 0.8046 - val_loss: 1.1536 - val_accuracy: 0.7010\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7887 - accuracy: 0.8121 - val_loss: 1.0252 - val_accuracy: 0.7474\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7627 - accuracy: 0.8201 - val_loss: 0.8467 - val_accuracy: 0.7944\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7440 - accuracy: 0.8260 - val_loss: 0.8980 - val_accuracy: 0.7950\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7376 - accuracy: 0.8270 - val_loss: 0.8176 - val_accuracy: 0.8112\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7217 - accuracy: 0.8360 - val_loss: 1.0056 - val_accuracy: 0.7584\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7079 - accuracy: 0.8390 - val_loss: 0.8933 - val_accuracy: 0.7848\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6885 - accuracy: 0.8424 - val_loss: 0.9389 - val_accuracy: 0.7652\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6790 - accuracy: 0.8452 - val_loss: 0.7582 - val_accuracy: 0.8260\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6663 - accuracy: 0.8478 - val_loss: 0.8897 - val_accuracy: 0.7891\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6591 - accuracy: 0.8536 - val_loss: 0.8002 - val_accuracy: 0.8094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 21/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6578 - accuracy: 0.8528 - val_loss: 0.8800 - val_accuracy: 0.7863\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 22/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6445 - accuracy: 0.8558 - val_loss: 0.8961 - val_accuracy: 0.7733\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 23/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6373 - accuracy: 0.8588 - val_loss: 1.0500 - val_accuracy: 0.7573\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 24/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6340 - accuracy: 0.8577 - val_loss: 0.7929 - val_accuracy: 0.8077\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 25/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6232 - accuracy: 0.8639 - val_loss: 0.7943 - val_accuracy: 0.8162\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 26/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6190 - accuracy: 0.8663 - val_loss: 0.8167 - val_accuracy: 0.8151\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 27/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6201 - accuracy: 0.8613 - val_loss: 0.8495 - val_accuracy: 0.8018\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 28/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6029 - accuracy: 0.8695 - val_loss: 0.8174 - val_accuracy: 0.8130\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 29/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6010 - accuracy: 0.8676 - val_loss: 0.7656 - val_accuracy: 0.8239\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 30/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5878 - accuracy: 0.8748 - val_loss: 0.7613 - val_accuracy: 0.8284\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 31/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5846 - accuracy: 0.8768 - val_loss: 0.8379 - val_accuracy: 0.8081\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 32/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5923 - accuracy: 0.8726 - val_loss: 0.8203 - val_accuracy: 0.8105\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 33/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5880 - accuracy: 0.8725 - val_loss: 0.8335 - val_accuracy: 0.8145\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 34/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5850 - accuracy: 0.8746 - val_loss: 0.8977 - val_accuracy: 0.7943\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 35/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5783 - accuracy: 0.8774 - val_loss: 1.1796 - val_accuracy: 0.7154\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 36/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5761 - accuracy: 0.8759 - val_loss: 0.8065 - val_accuracy: 0.8069\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 37/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5724 - accuracy: 0.8775 - val_loss: 0.8949 - val_accuracy: 0.7997\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 38/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5660 - accuracy: 0.8778 - val_loss: 0.7801 - val_accuracy: 0.8298\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 39/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5632 - accuracy: 0.8811 - val_loss: 0.6116 - val_accuracy: 0.8645\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 40/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5576 - accuracy: 0.8839 - val_loss: 0.8389 - val_accuracy: 0.8100\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 41/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5551 - accuracy: 0.8832 - val_loss: 0.8217 - val_accuracy: 0.8116\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 42/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5513 - accuracy: 0.8854 - val_loss: 0.6911 - val_accuracy: 0.8453\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 43/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5561 - accuracy: 0.8826 - val_loss: 0.8573 - val_accuracy: 0.8069\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 44/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5601 - accuracy: 0.8819 - val_loss: 0.8947 - val_accuracy: 0.7929\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 45/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5499 - accuracy: 0.8849 - val_loss: 0.7469 - val_accuracy: 0.8260\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 46/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5562 - accuracy: 0.8828 - val_loss: 0.8278 - val_accuracy: 0.8122\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 47/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5429 - accuracy: 0.8871 - val_loss: 0.8999 - val_accuracy: 0.7917\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 48/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5342 - accuracy: 0.8883 - val_loss: 0.6976 - val_accuracy: 0.8461\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 49/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5410 - accuracy: 0.8879 - val_loss: 0.7557 - val_accuracy: 0.8187\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 50/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5383 - accuracy: 0.8882 - val_loss: 0.6660 - val_accuracy: 0.8554\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 51/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5352 - accuracy: 0.8890 - val_loss: 0.6846 - val_accuracy: 0.8406\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 52/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.5355 - accuracy: 0.8883 - val_loss: 0.9030 - val_accuracy: 0.7880\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 53/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5255 - accuracy: 0.8928 - val_loss: 0.7496 - val_accuracy: 0.8315\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 54/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5275 - accuracy: 0.8931 - val_loss: 0.8960 - val_accuracy: 0.7942\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 55/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5241 - accuracy: 0.8912 - val_loss: 0.6590 - val_accuracy: 0.8552\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 56/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5225 - accuracy: 0.8938 - val_loss: 0.6914 - val_accuracy: 0.8453\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 57/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5236 - accuracy: 0.8916 - val_loss: 0.7121 - val_accuracy: 0.8371\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 58/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5291 - accuracy: 0.8915 - val_loss: 0.6276 - val_accuracy: 0.8644\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 59/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5135 - accuracy: 0.8963 - val_loss: 0.7552 - val_accuracy: 0.8274\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 60/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5134 - accuracy: 0.8944 - val_loss: 0.8169 - val_accuracy: 0.8139\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 61/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5119 - accuracy: 0.8948 - val_loss: 0.7701 - val_accuracy: 0.8219\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 62/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5185 - accuracy: 0.8928 - val_loss: 0.6299 - val_accuracy: 0.8588\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 63/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5179 - accuracy: 0.8946 - val_loss: 0.6892 - val_accuracy: 0.8552\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 64/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5193 - accuracy: 0.8939 - val_loss: 0.6621 - val_accuracy: 0.8508\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 65/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5112 - accuracy: 0.8948 - val_loss: 0.7341 - val_accuracy: 0.8363\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 66/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5042 - accuracy: 0.8970 - val_loss: 0.6354 - val_accuracy: 0.8592\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 67/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5111 - accuracy: 0.8949 - val_loss: 0.5823 - val_accuracy: 0.8755\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 68/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5017 - accuracy: 0.8979 - val_loss: 0.6591 - val_accuracy: 0.8512\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 69/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5023 - accuracy: 0.8981 - val_loss: 0.6868 - val_accuracy: 0.8512\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 70/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4984 - accuracy: 0.8984 - val_loss: 0.6702 - val_accuracy: 0.8573\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 71/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5009 - accuracy: 0.8983 - val_loss: 0.6700 - val_accuracy: 0.8493\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 72/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4970 - accuracy: 0.8987 - val_loss: 0.6941 - val_accuracy: 0.8442\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 73/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4959 - accuracy: 0.8991 - val_loss: 0.9080 - val_accuracy: 0.7940\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 74/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.4946 - accuracy: 0.8984 - val_loss: 0.9690 - val_accuracy: 0.7819\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 75/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5041 - accuracy: 0.8951 - val_loss: 0.7371 - val_accuracy: 0.8395\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 76/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4995 - accuracy: 0.8992 - val_loss: 0.6176 - val_accuracy: 0.8637\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 77/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4845 - accuracy: 0.9011 - val_loss: 0.8088 - val_accuracy: 0.8244\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 78/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4893 - accuracy: 0.9008 - val_loss: 0.7224 - val_accuracy: 0.8455\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 79/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4897 - accuracy: 0.9002 - val_loss: 0.6801 - val_accuracy: 0.8516\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 80/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4901 - accuracy: 0.9011 - val_loss: 0.6220 - val_accuracy: 0.8565\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 81/200\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4824 - accuracy: 0.9027 - val_loss: 0.7828 - val_accuracy: 0.8278\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 82/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4305 - accuracy: 0.9240 - val_loss: 0.4875 - val_accuracy: 0.9061\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 83/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.3770 - accuracy: 0.9402 - val_loss: 0.4819 - val_accuracy: 0.9077\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 84/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.3639 - accuracy: 0.9445 - val_loss: 0.4652 - val_accuracy: 0.9078\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 85/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3584 - accuracy: 0.9428 - val_loss: 0.4636 - val_accuracy: 0.9113\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 86/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3431 - accuracy: 0.9477 - val_loss: 0.4625 - val_accuracy: 0.9092\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 87/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3304 - accuracy: 0.9501 - val_loss: 0.4528 - val_accuracy: 0.9128\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 88/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3272 - accuracy: 0.9514 - val_loss: 0.4547 - val_accuracy: 0.9124\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 89/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3150 - accuracy: 0.9549 - val_loss: 0.4598 - val_accuracy: 0.9107\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 90/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3117 - accuracy: 0.9534 - val_loss: 0.4578 - val_accuracy: 0.9119\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 91/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3056 - accuracy: 0.9555 - val_loss: 0.4442 - val_accuracy: 0.9170\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 92/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3065 - accuracy: 0.9538 - val_loss: 0.4457 - val_accuracy: 0.9125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 93/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2992 - accuracy: 0.9555 - val_loss: 0.4541 - val_accuracy: 0.9125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 94/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2913 - accuracy: 0.9587 - val_loss: 0.4384 - val_accuracy: 0.9153\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 95/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2867 - accuracy: 0.9593 - val_loss: 0.4414 - val_accuracy: 0.9138\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 96/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.2817 - accuracy: 0.9604 - val_loss: 0.4387 - val_accuracy: 0.9152\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 97/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.2806 - accuracy: 0.9592 - val_loss: 0.4369 - val_accuracy: 0.9141\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 98/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.2748 - accuracy: 0.9606 - val_loss: 0.4369 - val_accuracy: 0.9139\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 99/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.2711 - accuracy: 0.9621 - val_loss: 0.4410 - val_accuracy: 0.9130\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 100/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2677 - accuracy: 0.9622 - val_loss: 0.4328 - val_accuracy: 0.9147\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 101/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2627 - accuracy: 0.9628 - val_loss: 0.4371 - val_accuracy: 0.9152\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 102/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2600 - accuracy: 0.9646 - val_loss: 0.4372 - val_accuracy: 0.9121\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 103/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2555 - accuracy: 0.9657 - val_loss: 0.4453 - val_accuracy: 0.9128\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 104/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2583 - accuracy: 0.9635 - val_loss: 0.4416 - val_accuracy: 0.9157\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 105/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.2475 - accuracy: 0.9681 - val_loss: 0.4452 - val_accuracy: 0.9116\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 106/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.2504 - accuracy: 0.9658 - val_loss: 0.4440 - val_accuracy: 0.9116\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 107/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2453 - accuracy: 0.9659 - val_loss: 0.4297 - val_accuracy: 0.9163\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 108/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2396 - accuracy: 0.9678 - val_loss: 0.4365 - val_accuracy: 0.9139\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 109/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2409 - accuracy: 0.9674 - val_loss: 0.4337 - val_accuracy: 0.9154\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 110/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.2389 - accuracy: 0.9674 - val_loss: 0.4396 - val_accuracy: 0.9133\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 111/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2349 - accuracy: 0.9693 - val_loss: 0.4417 - val_accuracy: 0.9142\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 112/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2348 - accuracy: 0.9690 - val_loss: 0.4489 - val_accuracy: 0.9128\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 113/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2313 - accuracy: 0.9685 - val_loss: 0.4452 - val_accuracy: 0.9123\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 114/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.2298 - accuracy: 0.9691 - val_loss: 0.4304 - val_accuracy: 0.9153\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 115/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2273 - accuracy: 0.9686 - val_loss: 0.4487 - val_accuracy: 0.9125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 116/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2254 - accuracy: 0.9707 - val_loss: 0.4437 - val_accuracy: 0.9131\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 117/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.2209 - accuracy: 0.9712 - val_loss: 0.4359 - val_accuracy: 0.9139\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 118/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2222 - accuracy: 0.9702 - val_loss: 0.4301 - val_accuracy: 0.9153\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 119/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2154 - accuracy: 0.9724 - val_loss: 0.4436 - val_accuracy: 0.9113\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 120/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2176 - accuracy: 0.9715 - val_loss: 0.4371 - val_accuracy: 0.9151\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 121/200\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2124 - accuracy: 0.9731 - val_loss: 0.4499 - val_accuracy: 0.9118\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 122/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2088 - accuracy: 0.9743 - val_loss: 0.4265 - val_accuracy: 0.9191\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 123/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2040 - accuracy: 0.9756 - val_loss: 0.4262 - val_accuracy: 0.9188\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 124/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2017 - accuracy: 0.9762 - val_loss: 0.4252 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 125/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2006 - accuracy: 0.9773 - val_loss: 0.4241 - val_accuracy: 0.9198\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 126/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1977 - accuracy: 0.9778 - val_loss: 0.4252 - val_accuracy: 0.9190\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 127/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2005 - accuracy: 0.9769 - val_loss: 0.4224 - val_accuracy: 0.9201\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 128/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1993 - accuracy: 0.9776 - val_loss: 0.4230 - val_accuracy: 0.9192\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 129/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1946 - accuracy: 0.9792 - val_loss: 0.4216 - val_accuracy: 0.9199\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 130/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1959 - accuracy: 0.9791 - val_loss: 0.4226 - val_accuracy: 0.9210\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 131/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1945 - accuracy: 0.9793 - val_loss: 0.4228 - val_accuracy: 0.9202\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 132/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1967 - accuracy: 0.9786 - val_loss: 0.4245 - val_accuracy: 0.9186\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 133/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1923 - accuracy: 0.9799 - val_loss: 0.4228 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 134/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1901 - accuracy: 0.9809 - val_loss: 0.4229 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 135/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1940 - accuracy: 0.9789 - val_loss: 0.4222 - val_accuracy: 0.9197\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 136/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1927 - accuracy: 0.9797 - val_loss: 0.4210 - val_accuracy: 0.9182\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 137/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1929 - accuracy: 0.9792 - val_loss: 0.4229 - val_accuracy: 0.9204\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 138/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1941 - accuracy: 0.9786 - val_loss: 0.4215 - val_accuracy: 0.9209\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 139/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1922 - accuracy: 0.9799 - val_loss: 0.4208 - val_accuracy: 0.9195\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 140/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1898 - accuracy: 0.9802 - val_loss: 0.4223 - val_accuracy: 0.9199\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 141/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1917 - accuracy: 0.9800 - val_loss: 0.4230 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 142/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1944 - accuracy: 0.9792 - val_loss: 0.4221 - val_accuracy: 0.9205\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 143/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1917 - accuracy: 0.9791 - val_loss: 0.4243 - val_accuracy: 0.9186\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 144/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1889 - accuracy: 0.9800 - val_loss: 0.4236 - val_accuracy: 0.9194\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 145/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1894 - accuracy: 0.9805 - val_loss: 0.4244 - val_accuracy: 0.9191\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 146/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1898 - accuracy: 0.9799 - val_loss: 0.4231 - val_accuracy: 0.9190\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 147/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1879 - accuracy: 0.9805 - val_loss: 0.4221 - val_accuracy: 0.9195\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 148/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1908 - accuracy: 0.9797 - val_loss: 0.4231 - val_accuracy: 0.9194\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 149/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1872 - accuracy: 0.9808 - val_loss: 0.4227 - val_accuracy: 0.9195\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 150/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1883 - accuracy: 0.9801 - val_loss: 0.4265 - val_accuracy: 0.9185\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 151/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1885 - accuracy: 0.9794 - val_loss: 0.4248 - val_accuracy: 0.9186\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 152/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1863 - accuracy: 0.9816 - val_loss: 0.4228 - val_accuracy: 0.9194\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 153/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1854 - accuracy: 0.9819 - val_loss: 0.4241 - val_accuracy: 0.9196\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 154/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1855 - accuracy: 0.9817 - val_loss: 0.4234 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 155/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1836 - accuracy: 0.9825 - val_loss: 0.4250 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 156/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1859 - accuracy: 0.9808 - val_loss: 0.4250 - val_accuracy: 0.9177\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 157/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1853 - accuracy: 0.9818 - val_loss: 0.4234 - val_accuracy: 0.9186\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 158/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1856 - accuracy: 0.9806 - val_loss: 0.4284 - val_accuracy: 0.9174\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 159/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1863 - accuracy: 0.9805 - val_loss: 0.4252 - val_accuracy: 0.9171\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 160/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1852 - accuracy: 0.9811 - val_loss: 0.4231 - val_accuracy: 0.9188\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 161/200\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1838 - accuracy: 0.9812 - val_loss: 0.4260 - val_accuracy: 0.9183\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 162/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1840 - accuracy: 0.9817 - val_loss: 0.4257 - val_accuracy: 0.9185\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 163/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1862 - accuracy: 0.9802 - val_loss: 0.4246 - val_accuracy: 0.9188\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 164/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1840 - accuracy: 0.9821 - val_loss: 0.4254 - val_accuracy: 0.9194\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 165/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1859 - accuracy: 0.9806 - val_loss: 0.4220 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 166/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1831 - accuracy: 0.9810 - val_loss: 0.4250 - val_accuracy: 0.9190\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 167/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1839 - accuracy: 0.9815 - val_loss: 0.4248 - val_accuracy: 0.9191\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 168/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1842 - accuracy: 0.9809 - val_loss: 0.4251 - val_accuracy: 0.9187\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 169/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1863 - accuracy: 0.9804 - val_loss: 0.4242 - val_accuracy: 0.9188\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 170/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1826 - accuracy: 0.9823 - val_loss: 0.4245 - val_accuracy: 0.9198\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 171/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1833 - accuracy: 0.9819 - val_loss: 0.4254 - val_accuracy: 0.9192\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 172/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1812 - accuracy: 0.9823 - val_loss: 0.4260 - val_accuracy: 0.9182\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 173/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.1802 - accuracy: 0.9824 - val_loss: 0.4240 - val_accuracy: 0.9187\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 174/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1859 - accuracy: 0.9803 - val_loss: 0.4259 - val_accuracy: 0.9177\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 175/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1802 - accuracy: 0.9823 - val_loss: 0.4246 - val_accuracy: 0.9188\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 176/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1832 - accuracy: 0.9813 - val_loss: 0.4255 - val_accuracy: 0.9181\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 177/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1825 - accuracy: 0.9822 - val_loss: 0.4232 - val_accuracy: 0.9183\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 178/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1832 - accuracy: 0.9826 - val_loss: 0.4251 - val_accuracy: 0.9190\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 179/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1803 - accuracy: 0.9825 - val_loss: 0.4254 - val_accuracy: 0.9190\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 180/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1836 - accuracy: 0.9817 - val_loss: 0.4238 - val_accuracy: 0.9203\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 181/200\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1854 - accuracy: 0.9803 - val_loss: 0.4260 - val_accuracy: 0.9192\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 182/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1823 - accuracy: 0.9823 - val_loss: 0.4256 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 183/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1817 - accuracy: 0.9823 - val_loss: 0.4235 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 184/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1831 - accuracy: 0.9806 - val_loss: 0.4273 - val_accuracy: 0.9178\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 185/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1837 - accuracy: 0.9812 - val_loss: 0.4261 - val_accuracy: 0.9179\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 186/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1820 - accuracy: 0.9824 - val_loss: 0.4244 - val_accuracy: 0.9193\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 187/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1823 - accuracy: 0.9820 - val_loss: 0.4244 - val_accuracy: 0.9191\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 188/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1830 - accuracy: 0.9814 - val_loss: 0.4251 - val_accuracy: 0.9200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 189/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1846 - accuracy: 0.9806 - val_loss: 0.4239 - val_accuracy: 0.9190\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 190/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1815 - accuracy: 0.9819 - val_loss: 0.4251 - val_accuracy: 0.9187\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 191/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1831 - accuracy: 0.9817 - val_loss: 0.4251 - val_accuracy: 0.9183\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 192/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.1842 - accuracy: 0.9811 - val_loss: 0.4239 - val_accuracy: 0.9183\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 193/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1855 - accuracy: 0.9805 - val_loss: 0.4242 - val_accuracy: 0.9192\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 194/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1828 - accuracy: 0.9812 - val_loss: 0.4252 - val_accuracy: 0.9182\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 195/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1833 - accuracy: 0.9809 - val_loss: 0.4234 - val_accuracy: 0.9194\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 196/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1827 - accuracy: 0.9812 - val_loss: 0.4247 - val_accuracy: 0.9203\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 197/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1807 - accuracy: 0.9822 - val_loss: 0.4254 - val_accuracy: 0.9185\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 198/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1794 - accuracy: 0.9824 - val_loss: 0.4253 - val_accuracy: 0.9190\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 199/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1841 - accuracy: 0.9818 - val_loss: 0.4257 - val_accuracy: 0.9192\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 200/200\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.1817 - accuracy: 0.9812 - val_loss: 0.4250 - val_accuracy: 0.9187\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4250 - accuracy: 0.9187\n",
            "Test loss: 0.4249984920024872\n",
            "Test accuracy: 0.9186999797821045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D8rIybifkay"
      },
      "source": [
        "VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3ycPi0QXfA1",
        "outputId": "9b6b2f7b-53ab-4027-aa23-588135d91753"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import keras\r\n",
        "from keras.datasets import cifar10\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\r\n",
        "from keras import optimizers\r\n",
        "import numpy as np\r\n",
        "from keras.layers.core import Lambda\r\n",
        "from keras import backend as K\r\n",
        "from keras import regularizers\r\n",
        "\r\n",
        "class cifar10vgg:\r\n",
        "    def __init__(self,train=True):\r\n",
        "        self.num_classes = 10\r\n",
        "        self.weight_decay = 0.0005\r\n",
        "        self.x_shape = [32,32,3]\r\n",
        "\r\n",
        "        self.model = self.build_model()\r\n",
        "        if train:\r\n",
        "            self.model = self.train(self.model)\r\n",
        "        else:\r\n",
        "            self.model.load_weights('cifar10vgg.h5')\r\n",
        "\r\n",
        "\r\n",
        "    def build_model(self):\r\n",
        "        model = Sequential()\r\n",
        "        weight_decay = self.weight_decay\r\n",
        "\r\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',\r\n",
        "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(0.3))\r\n",
        "\r\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "\r\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(0.4))\r\n",
        "\r\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "\r\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(0.4))\r\n",
        "\r\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(0.4))\r\n",
        "\r\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "\r\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "\r\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(0.4))\r\n",
        "\r\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(0.4))\r\n",
        "\r\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "\r\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "\r\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(0.4))\r\n",
        "\r\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(Dropout(0.4))\r\n",
        "\r\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "\r\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "        model.add(Dropout(0.5))\r\n",
        "\r\n",
        "        model.add(Flatten())\r\n",
        "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\r\n",
        "        model.add(Activation('relu'))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "\r\n",
        "        model.add(Dropout(0.5))\r\n",
        "        model.add(Dense(self.num_classes))\r\n",
        "        model.add(Activation('softmax'))\r\n",
        "        return model\r\n",
        "\r\n",
        "\r\n",
        "    def normalize(self,X_train,X_test):\r\n",
        "        #this function normalize inputs for zero mean and unit variance\r\n",
        "        # it is used when training a model.\r\n",
        "        # Input: training set and test set\r\n",
        "        # Output: normalized training set and test set according to the trianing set statistics.\r\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\r\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\r\n",
        "        X_train = (X_train-mean)/(std+1e-7)\r\n",
        "        X_test = (X_test-mean)/(std+1e-7)\r\n",
        "        return X_train, X_test\r\n",
        "\r\n",
        "    def normalize_production(self,x):\r\n",
        "        #this function is used to normalize instances in production according to saved training set statistics\r\n",
        "        # Input: X - a training set\r\n",
        "        # Output X - a normalized training set according to normalization constants.\r\n",
        "\r\n",
        "        #these values produced during first training and are general for the standard cifar10 training set normalization\r\n",
        "        mean = 120.707\r\n",
        "        std = 64.15\r\n",
        "        return (x-mean)/(std+1e-7)\r\n",
        "\r\n",
        "    def predict(self,x,normalize=True,batch_size=50):\r\n",
        "        if normalize:\r\n",
        "            x = self.normalize_production(x)\r\n",
        "        return self.model.predict(x,batch_size)\r\n",
        "\r\n",
        "    def train(self,model):\r\n",
        "\r\n",
        "        #training parameters\r\n",
        "        batch_size = 128\r\n",
        "        maxepoches = 200\r\n",
        "        learning_rate = 0.1\r\n",
        "        lr_decay = 1e-6\r\n",
        "        lr_drop = 20\r\n",
        "        # The data, shuffled and split between train and test sets:\r\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n",
        "        x_train = x_train.astype('float32')\r\n",
        "        x_test = x_test.astype('float32')\r\n",
        "        x_train, x_test = self.normalize(x_train, x_test)\r\n",
        "\r\n",
        "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\r\n",
        "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\r\n",
        "\r\n",
        "        def lr_scheduler(epoch):\r\n",
        "            return learning_rate * (0.5 ** (epoch // lr_drop))\r\n",
        "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\r\n",
        "\r\n",
        "        #data augmentation\r\n",
        "        datagen = ImageDataGenerator(\r\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\r\n",
        "            samplewise_center=False,  # set each sample mean to 0\r\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\r\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\r\n",
        "            zca_whitening=False,  # apply ZCA whitening\r\n",
        "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\r\n",
        "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\r\n",
        "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\r\n",
        "            horizontal_flip=True,  # randomly flip images\r\n",
        "            vertical_flip=False)  # randomly flip images\r\n",
        "        # (std, mean, and principal components if ZCA whitening is applied).\r\n",
        "        datagen.fit(x_train)\r\n",
        "\r\n",
        "\r\n",
        "        #optimization details\r\n",
        "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\r\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "        # 在訓練過程中，learning rate每25個循環下降一次\r\n",
        "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\r\n",
        "                                         batch_size=batch_size),\r\n",
        "                            steps_per_epoch=x_train.shape[0] // batch_size,\r\n",
        "                            epochs=maxepoches,\r\n",
        "                            validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\r\n",
        "        model.save_weights('cifar10vgg.h5')\r\n",
        "        return model\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "\r\n",
        "\r\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n",
        "    x_train = x_train.astype('float32')\r\n",
        "    x_test = x_test.astype('float32')\r\n",
        "\r\n",
        "    y_train = keras.utils.to_categorical(y_train, 10)\r\n",
        "    y_test = keras.utils.to_categorical(y_test, 10)\r\n",
        "\r\n",
        "    model = cifar10vgg()\r\n",
        "\r\n",
        "    predicted_x = model.predict(x_test)\r\n",
        "    residuals = np.argmax(predicted_x,1)!=np.argmax(y_test,1)\r\n",
        "\r\n",
        "    loss = sum(residuals)/len(residuals)\r\n",
        "    print(\"the validation 0/1 loss is: \",loss)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "390/390 - 37s - loss: 21.6811 - accuracy: 0.1726 - val_loss: 16.1798 - val_accuracy: 0.1725\n",
            "Epoch 2/200\n",
            "390/390 - 27s - loss: 11.5611 - accuracy: 0.2581 - val_loss: 8.9732 - val_accuracy: 0.1595\n",
            "Epoch 3/200\n",
            "390/390 - 27s - loss: 6.1969 - accuracy: 0.3408 - val_loss: 5.6921 - val_accuracy: 0.1505\n",
            "Epoch 4/200\n",
            "390/390 - 28s - loss: 3.6815 - accuracy: 0.4438 - val_loss: 3.3507 - val_accuracy: 0.3650\n",
            "Epoch 5/200\n",
            "390/390 - 28s - loss: 2.4949 - accuracy: 0.5267 - val_loss: 2.2825 - val_accuracy: 0.5116\n",
            "Epoch 6/200\n",
            "390/390 - 28s - loss: 1.9497 - accuracy: 0.5842 - val_loss: 1.9409 - val_accuracy: 0.5876\n",
            "Epoch 7/200\n",
            "390/390 - 28s - loss: 1.7026 - accuracy: 0.6256 - val_loss: 1.5092 - val_accuracy: 0.6682\n",
            "Epoch 8/200\n",
            "390/390 - 28s - loss: 1.5628 - accuracy: 0.6563 - val_loss: 1.4948 - val_accuracy: 0.6790\n",
            "Epoch 9/200\n",
            "390/390 - 28s - loss: 1.5377 - accuracy: 0.6680 - val_loss: 1.4796 - val_accuracy: 0.6839\n",
            "Epoch 10/200\n",
            "390/390 - 28s - loss: 1.4894 - accuracy: 0.6856 - val_loss: 1.3647 - val_accuracy: 0.7185\n",
            "Epoch 11/200\n",
            "390/390 - 28s - loss: 1.4716 - accuracy: 0.6989 - val_loss: 1.5710 - val_accuracy: 0.6772\n",
            "Epoch 12/200\n",
            "390/390 - 28s - loss: 1.4616 - accuracy: 0.7081 - val_loss: 1.5396 - val_accuracy: 0.6952\n",
            "Epoch 13/200\n",
            "390/390 - 28s - loss: 1.4675 - accuracy: 0.7116 - val_loss: 1.5573 - val_accuracy: 0.6901\n",
            "Epoch 14/200\n",
            "390/390 - 28s - loss: 1.4704 - accuracy: 0.7180 - val_loss: 1.5618 - val_accuracy: 0.7059\n",
            "Epoch 15/200\n",
            "390/390 - 28s - loss: 1.4663 - accuracy: 0.7228 - val_loss: 1.7362 - val_accuracy: 0.6539\n",
            "Epoch 16/200\n",
            "390/390 - 28s - loss: 1.4828 - accuracy: 0.7226 - val_loss: 1.3868 - val_accuracy: 0.7585\n",
            "Epoch 17/200\n",
            "390/390 - 28s - loss: 1.4868 - accuracy: 0.7296 - val_loss: 1.4566 - val_accuracy: 0.7293\n",
            "Epoch 18/200\n",
            "390/390 - 28s - loss: 1.4946 - accuracy: 0.7275 - val_loss: 1.4913 - val_accuracy: 0.7376\n",
            "Epoch 19/200\n",
            "390/390 - 28s - loss: 1.5011 - accuracy: 0.7338 - val_loss: 1.3993 - val_accuracy: 0.7724\n",
            "Epoch 20/200\n",
            "390/390 - 28s - loss: 1.5030 - accuracy: 0.7335 - val_loss: 1.4864 - val_accuracy: 0.7405\n",
            "Epoch 21/200\n",
            "390/390 - 28s - loss: 1.3297 - accuracy: 0.7755 - val_loss: 1.1540 - val_accuracy: 0.8258\n",
            "Epoch 22/200\n",
            "390/390 - 28s - loss: 1.2338 - accuracy: 0.7841 - val_loss: 1.1492 - val_accuracy: 0.7990\n",
            "Epoch 23/200\n",
            "390/390 - 28s - loss: 1.2032 - accuracy: 0.7863 - val_loss: 1.2189 - val_accuracy: 0.7848\n",
            "Epoch 24/200\n",
            "390/390 - 28s - loss: 1.1913 - accuracy: 0.7893 - val_loss: 1.1140 - val_accuracy: 0.8128\n",
            "Epoch 25/200\n",
            "390/390 - 28s - loss: 1.2049 - accuracy: 0.7851 - val_loss: 1.2445 - val_accuracy: 0.7837\n",
            "Epoch 26/200\n",
            "390/390 - 28s - loss: 1.2021 - accuracy: 0.7913 - val_loss: 1.1858 - val_accuracy: 0.7955\n",
            "Epoch 27/200\n",
            "390/390 - 28s - loss: 1.2047 - accuracy: 0.7906 - val_loss: 1.2844 - val_accuracy: 0.7752\n",
            "Epoch 28/200\n",
            "390/390 - 28s - loss: 1.1983 - accuracy: 0.7942 - val_loss: 1.2100 - val_accuracy: 0.7922\n",
            "Epoch 29/200\n",
            "390/390 - 28s - loss: 1.2117 - accuracy: 0.7915 - val_loss: 1.1389 - val_accuracy: 0.8213\n",
            "Epoch 30/200\n",
            "390/390 - 28s - loss: 1.2127 - accuracy: 0.7949 - val_loss: 1.1129 - val_accuracy: 0.8273\n",
            "Epoch 31/200\n",
            "390/390 - 28s - loss: 1.2190 - accuracy: 0.7948 - val_loss: 1.2776 - val_accuracy: 0.7803\n",
            "Epoch 32/200\n",
            "390/390 - 28s - loss: 1.2184 - accuracy: 0.7977 - val_loss: 1.1781 - val_accuracy: 0.8104\n",
            "Epoch 33/200\n",
            "390/390 - 28s - loss: 1.2222 - accuracy: 0.7984 - val_loss: 1.1926 - val_accuracy: 0.8140\n",
            "Epoch 34/200\n",
            "390/390 - 28s - loss: 1.2231 - accuracy: 0.7988 - val_loss: 1.1624 - val_accuracy: 0.8253\n",
            "Epoch 35/200\n",
            "390/390 - 28s - loss: 1.2187 - accuracy: 0.8004 - val_loss: 1.1428 - val_accuracy: 0.8264\n",
            "Epoch 36/200\n",
            "390/390 - 28s - loss: 1.2227 - accuracy: 0.7975 - val_loss: 1.2394 - val_accuracy: 0.7959\n",
            "Epoch 37/200\n",
            "390/390 - 28s - loss: 1.2089 - accuracy: 0.8053 - val_loss: 1.1604 - val_accuracy: 0.8178\n",
            "Epoch 38/200\n",
            "390/390 - 28s - loss: 1.2166 - accuracy: 0.8038 - val_loss: 1.1007 - val_accuracy: 0.8418\n",
            "Epoch 39/200\n",
            "390/390 - 28s - loss: 1.2158 - accuracy: 0.8049 - val_loss: 1.1071 - val_accuracy: 0.8393\n",
            "Epoch 40/200\n",
            "390/390 - 28s - loss: 1.2243 - accuracy: 0.8024 - val_loss: 1.1638 - val_accuracy: 0.8277\n",
            "Epoch 41/200\n",
            "390/390 - 28s - loss: 1.0972 - accuracy: 0.8365 - val_loss: 1.0188 - val_accuracy: 0.8536\n",
            "Epoch 42/200\n",
            "390/390 - 28s - loss: 1.0269 - accuracy: 0.8443 - val_loss: 0.9782 - val_accuracy: 0.8561\n",
            "Epoch 43/200\n",
            "390/390 - 28s - loss: 0.9925 - accuracy: 0.8456 - val_loss: 0.9321 - val_accuracy: 0.8643\n",
            "Epoch 44/200\n",
            "390/390 - 28s - loss: 0.9758 - accuracy: 0.8453 - val_loss: 0.9057 - val_accuracy: 0.8673\n",
            "Epoch 45/200\n",
            "390/390 - 28s - loss: 0.9688 - accuracy: 0.8426 - val_loss: 1.0101 - val_accuracy: 0.8323\n",
            "Epoch 46/200\n",
            "390/390 - 28s - loss: 0.9620 - accuracy: 0.8444 - val_loss: 0.8878 - val_accuracy: 0.8683\n",
            "Epoch 47/200\n",
            "390/390 - 28s - loss: 0.9558 - accuracy: 0.8442 - val_loss: 1.0046 - val_accuracy: 0.8344\n",
            "Epoch 48/200\n",
            "390/390 - 28s - loss: 0.9553 - accuracy: 0.8447 - val_loss: 0.9542 - val_accuracy: 0.8488\n",
            "Epoch 49/200\n",
            "390/390 - 28s - loss: 0.9597 - accuracy: 0.8441 - val_loss: 0.9473 - val_accuracy: 0.8498\n",
            "Epoch 50/200\n",
            "390/390 - 28s - loss: 0.9574 - accuracy: 0.8446 - val_loss: 0.9341 - val_accuracy: 0.8556\n",
            "Epoch 51/200\n",
            "390/390 - 28s - loss: 0.9507 - accuracy: 0.8487 - val_loss: 0.9467 - val_accuracy: 0.8518\n",
            "Epoch 52/200\n",
            "390/390 - 28s - loss: 0.9507 - accuracy: 0.8497 - val_loss: 0.9991 - val_accuracy: 0.8345\n",
            "Epoch 53/200\n",
            "390/390 - 28s - loss: 0.9598 - accuracy: 0.8450 - val_loss: 0.8900 - val_accuracy: 0.8707\n",
            "Epoch 54/200\n",
            "390/390 - 28s - loss: 0.9587 - accuracy: 0.8496 - val_loss: 0.9044 - val_accuracy: 0.8663\n",
            "Epoch 55/200\n",
            "390/390 - 28s - loss: 0.9567 - accuracy: 0.8507 - val_loss: 0.9075 - val_accuracy: 0.8703\n",
            "Epoch 56/200\n",
            "390/390 - 28s - loss: 0.9616 - accuracy: 0.8485 - val_loss: 0.9018 - val_accuracy: 0.8704\n",
            "Epoch 57/200\n",
            "390/390 - 28s - loss: 0.9630 - accuracy: 0.8480 - val_loss: 0.9251 - val_accuracy: 0.8604\n",
            "Epoch 58/200\n",
            "390/390 - 28s - loss: 0.9696 - accuracy: 0.8463 - val_loss: 0.9244 - val_accuracy: 0.8655\n",
            "Epoch 59/200\n",
            "390/390 - 28s - loss: 0.9621 - accuracy: 0.8507 - val_loss: 0.9422 - val_accuracy: 0.8592\n",
            "Epoch 60/200\n",
            "390/390 - 28s - loss: 0.9586 - accuracy: 0.8525 - val_loss: 0.8971 - val_accuracy: 0.8733\n",
            "Epoch 61/200\n",
            "390/390 - 28s - loss: 0.8810 - accuracy: 0.8735 - val_loss: 0.7978 - val_accuracy: 0.8950\n",
            "Epoch 62/200\n",
            "390/390 - 28s - loss: 0.8247 - accuracy: 0.8848 - val_loss: 0.7921 - val_accuracy: 0.8932\n",
            "Epoch 63/200\n",
            "390/390 - 28s - loss: 0.8015 - accuracy: 0.8861 - val_loss: 0.7810 - val_accuracy: 0.8913\n",
            "Epoch 64/200\n",
            "390/390 - 28s - loss: 0.7882 - accuracy: 0.8859 - val_loss: 0.7872 - val_accuracy: 0.8850\n",
            "Epoch 65/200\n",
            "390/390 - 28s - loss: 0.7686 - accuracy: 0.8886 - val_loss: 0.7516 - val_accuracy: 0.8934\n",
            "Epoch 66/200\n",
            "390/390 - 28s - loss: 0.7584 - accuracy: 0.8876 - val_loss: 0.7655 - val_accuracy: 0.8856\n",
            "Epoch 67/200\n",
            "390/390 - 28s - loss: 0.7512 - accuracy: 0.8885 - val_loss: 0.7327 - val_accuracy: 0.8928\n",
            "Epoch 68/200\n",
            "390/390 - 28s - loss: 0.7504 - accuracy: 0.8868 - val_loss: 0.7762 - val_accuracy: 0.8792\n",
            "Epoch 69/200\n",
            "390/390 - 28s - loss: 0.7449 - accuracy: 0.8873 - val_loss: 0.7342 - val_accuracy: 0.8909\n",
            "Epoch 70/200\n",
            "390/390 - 28s - loss: 0.7435 - accuracy: 0.8867 - val_loss: 0.7742 - val_accuracy: 0.8785\n",
            "Epoch 71/200\n",
            "390/390 - 28s - loss: 0.7444 - accuracy: 0.8864 - val_loss: 0.7540 - val_accuracy: 0.8870\n",
            "Epoch 72/200\n",
            "390/390 - 28s - loss: 0.7365 - accuracy: 0.8879 - val_loss: 0.7157 - val_accuracy: 0.8976\n",
            "Epoch 73/200\n",
            "390/390 - 28s - loss: 0.7403 - accuracy: 0.8853 - val_loss: 0.7382 - val_accuracy: 0.8902\n",
            "Epoch 74/200\n",
            "390/390 - 28s - loss: 0.7415 - accuracy: 0.8854 - val_loss: 0.7312 - val_accuracy: 0.8925\n",
            "Epoch 75/200\n",
            "390/390 - 28s - loss: 0.7441 - accuracy: 0.8852 - val_loss: 0.7538 - val_accuracy: 0.8831\n",
            "Epoch 76/200\n",
            "390/390 - 28s - loss: 0.7380 - accuracy: 0.8878 - val_loss: 0.7558 - val_accuracy: 0.8835\n",
            "Epoch 77/200\n",
            "390/390 - 28s - loss: 0.7375 - accuracy: 0.8871 - val_loss: 0.7642 - val_accuracy: 0.8792\n",
            "Epoch 78/200\n",
            "390/390 - 28s - loss: 0.7358 - accuracy: 0.8872 - val_loss: 0.7449 - val_accuracy: 0.8850\n",
            "Epoch 79/200\n",
            "390/390 - 28s - loss: 0.7307 - accuracy: 0.8896 - val_loss: 0.7225 - val_accuracy: 0.8942\n",
            "Epoch 80/200\n",
            "390/390 - 28s - loss: 0.7320 - accuracy: 0.8888 - val_loss: 0.7260 - val_accuracy: 0.8912\n",
            "Epoch 81/200\n",
            "390/390 - 28s - loss: 0.6771 - accuracy: 0.9056 - val_loss: 0.7039 - val_accuracy: 0.8978\n",
            "Epoch 82/200\n",
            "390/390 - 28s - loss: 0.6463 - accuracy: 0.9122 - val_loss: 0.6434 - val_accuracy: 0.9129\n",
            "Epoch 83/200\n",
            "390/390 - 28s - loss: 0.6297 - accuracy: 0.9135 - val_loss: 0.6609 - val_accuracy: 0.9054\n",
            "Epoch 84/200\n",
            "390/390 - 28s - loss: 0.6194 - accuracy: 0.9167 - val_loss: 0.6310 - val_accuracy: 0.9144\n",
            "Epoch 85/200\n",
            "390/390 - 28s - loss: 0.6083 - accuracy: 0.9169 - val_loss: 0.6378 - val_accuracy: 0.9084\n",
            "Epoch 86/200\n",
            "390/390 - 28s - loss: 0.6023 - accuracy: 0.9159 - val_loss: 0.6260 - val_accuracy: 0.9120\n",
            "Epoch 87/200\n",
            "390/390 - 28s - loss: 0.5966 - accuracy: 0.9183 - val_loss: 0.6462 - val_accuracy: 0.9031\n",
            "Epoch 88/200\n",
            "390/390 - 28s - loss: 0.5881 - accuracy: 0.9191 - val_loss: 0.6053 - val_accuracy: 0.9169\n",
            "Epoch 89/200\n",
            "390/390 - 28s - loss: 0.5836 - accuracy: 0.9185 - val_loss: 0.6230 - val_accuracy: 0.9096\n",
            "Epoch 90/200\n",
            "390/390 - 28s - loss: 0.5833 - accuracy: 0.9173 - val_loss: 0.6034 - val_accuracy: 0.9140\n",
            "Epoch 91/200\n",
            "390/390 - 28s - loss: 0.5771 - accuracy: 0.9188 - val_loss: 0.6222 - val_accuracy: 0.9081\n",
            "Epoch 92/200\n",
            "390/390 - 28s - loss: 0.5733 - accuracy: 0.9184 - val_loss: 0.6064 - val_accuracy: 0.9119\n",
            "Epoch 93/200\n",
            "390/390 - 28s - loss: 0.5672 - accuracy: 0.9200 - val_loss: 0.6085 - val_accuracy: 0.9102\n",
            "Epoch 94/200\n",
            "390/390 - 28s - loss: 0.5690 - accuracy: 0.9184 - val_loss: 0.6193 - val_accuracy: 0.9054\n",
            "Epoch 95/200\n",
            "390/390 - 28s - loss: 0.5690 - accuracy: 0.9176 - val_loss: 0.6149 - val_accuracy: 0.9070\n",
            "Epoch 96/200\n",
            "390/390 - 28s - loss: 0.5635 - accuracy: 0.9178 - val_loss: 0.6311 - val_accuracy: 0.9033\n",
            "Epoch 97/200\n",
            "390/390 - 28s - loss: 0.5564 - accuracy: 0.9187 - val_loss: 0.5883 - val_accuracy: 0.9161\n",
            "Epoch 98/200\n",
            "390/390 - 28s - loss: 0.5627 - accuracy: 0.9181 - val_loss: 0.5990 - val_accuracy: 0.9079\n",
            "Epoch 99/200\n",
            "390/390 - 28s - loss: 0.5596 - accuracy: 0.9184 - val_loss: 0.6139 - val_accuracy: 0.9085\n",
            "Epoch 100/200\n",
            "390/390 - 28s - loss: 0.5600 - accuracy: 0.9181 - val_loss: 0.6065 - val_accuracy: 0.9098\n",
            "Epoch 101/200\n",
            "390/390 - 28s - loss: 0.5240 - accuracy: 0.9296 - val_loss: 0.5759 - val_accuracy: 0.9185\n",
            "Epoch 102/200\n",
            "390/390 - 28s - loss: 0.5011 - accuracy: 0.9359 - val_loss: 0.5725 - val_accuracy: 0.9186\n",
            "Epoch 103/200\n",
            "390/390 - 28s - loss: 0.4937 - accuracy: 0.9387 - val_loss: 0.5447 - val_accuracy: 0.9277\n",
            "Epoch 104/200\n",
            "390/390 - 28s - loss: 0.4812 - accuracy: 0.9404 - val_loss: 0.5745 - val_accuracy: 0.9187\n",
            "Epoch 105/200\n",
            "390/390 - 28s - loss: 0.4819 - accuracy: 0.9386 - val_loss: 0.5593 - val_accuracy: 0.9195\n",
            "Epoch 106/200\n",
            "390/390 - 28s - loss: 0.4703 - accuracy: 0.9415 - val_loss: 0.5584 - val_accuracy: 0.9213\n",
            "Epoch 107/200\n",
            "390/390 - 28s - loss: 0.4724 - accuracy: 0.9400 - val_loss: 0.5550 - val_accuracy: 0.9201\n",
            "Epoch 108/200\n",
            "390/390 - 28s - loss: 0.4645 - accuracy: 0.9406 - val_loss: 0.5361 - val_accuracy: 0.9247\n",
            "Epoch 109/200\n",
            "390/390 - 28s - loss: 0.4557 - accuracy: 0.9433 - val_loss: 0.5627 - val_accuracy: 0.9163\n",
            "Epoch 110/200\n",
            "390/390 - 28s - loss: 0.4542 - accuracy: 0.9422 - val_loss: 0.5559 - val_accuracy: 0.9190\n",
            "Epoch 111/200\n",
            "390/390 - 28s - loss: 0.4500 - accuracy: 0.9426 - val_loss: 0.5419 - val_accuracy: 0.9211\n",
            "Epoch 112/200\n",
            "390/390 - 28s - loss: 0.4540 - accuracy: 0.9409 - val_loss: 0.5658 - val_accuracy: 0.9128\n",
            "Epoch 113/200\n",
            "390/390 - 28s - loss: 0.4442 - accuracy: 0.9434 - val_loss: 0.5537 - val_accuracy: 0.9198\n",
            "Epoch 114/200\n",
            "390/390 - 28s - loss: 0.4465 - accuracy: 0.9412 - val_loss: 0.5580 - val_accuracy: 0.9162\n",
            "Epoch 115/200\n",
            "390/390 - 28s - loss: 0.4420 - accuracy: 0.9428 - val_loss: 0.5416 - val_accuracy: 0.9189\n",
            "Epoch 116/200\n",
            "390/390 - 28s - loss: 0.4362 - accuracy: 0.9450 - val_loss: 0.5424 - val_accuracy: 0.9173\n",
            "Epoch 117/200\n",
            "390/390 - 28s - loss: 0.4345 - accuracy: 0.9439 - val_loss: 0.5348 - val_accuracy: 0.9232\n",
            "Epoch 118/200\n",
            "390/390 - 28s - loss: 0.4347 - accuracy: 0.9432 - val_loss: 0.5293 - val_accuracy: 0.9219\n",
            "Epoch 119/200\n",
            "390/390 - 28s - loss: 0.4329 - accuracy: 0.9434 - val_loss: 0.5290 - val_accuracy: 0.9204\n",
            "Epoch 120/200\n",
            "390/390 - 28s - loss: 0.4289 - accuracy: 0.9437 - val_loss: 0.5434 - val_accuracy: 0.9157\n",
            "Epoch 121/200\n",
            "390/390 - 28s - loss: 0.4056 - accuracy: 0.9511 - val_loss: 0.5079 - val_accuracy: 0.9260\n",
            "Epoch 122/200\n",
            "390/390 - 28s - loss: 0.4002 - accuracy: 0.9536 - val_loss: 0.5246 - val_accuracy: 0.9228\n",
            "Epoch 123/200\n",
            "390/390 - 28s - loss: 0.3901 - accuracy: 0.9559 - val_loss: 0.5108 - val_accuracy: 0.9269\n",
            "Epoch 124/200\n",
            "390/390 - 28s - loss: 0.3842 - accuracy: 0.9573 - val_loss: 0.5202 - val_accuracy: 0.9245\n",
            "Epoch 125/200\n",
            "390/390 - 28s - loss: 0.3827 - accuracy: 0.9571 - val_loss: 0.5181 - val_accuracy: 0.9263\n",
            "Epoch 126/200\n",
            "390/390 - 28s - loss: 0.3773 - accuracy: 0.9580 - val_loss: 0.5114 - val_accuracy: 0.9272\n",
            "Epoch 127/200\n",
            "390/390 - 28s - loss: 0.3733 - accuracy: 0.9596 - val_loss: 0.5082 - val_accuracy: 0.9288\n",
            "Epoch 128/200\n",
            "390/390 - 28s - loss: 0.3725 - accuracy: 0.9587 - val_loss: 0.5088 - val_accuracy: 0.9264\n",
            "Epoch 129/200\n",
            "390/390 - 28s - loss: 0.3670 - accuracy: 0.9601 - val_loss: 0.5151 - val_accuracy: 0.9250\n",
            "Epoch 130/200\n",
            "390/390 - 28s - loss: 0.3669 - accuracy: 0.9587 - val_loss: 0.4998 - val_accuracy: 0.9276\n",
            "Epoch 131/200\n",
            "390/390 - 28s - loss: 0.3683 - accuracy: 0.9578 - val_loss: 0.4910 - val_accuracy: 0.9308\n",
            "Epoch 132/200\n",
            "390/390 - 28s - loss: 0.3558 - accuracy: 0.9623 - val_loss: 0.4999 - val_accuracy: 0.9286\n",
            "Epoch 133/200\n",
            "390/390 - 28s - loss: 0.3579 - accuracy: 0.9592 - val_loss: 0.5030 - val_accuracy: 0.9246\n",
            "Epoch 134/200\n",
            "390/390 - 28s - loss: 0.3559 - accuracy: 0.9610 - val_loss: 0.5041 - val_accuracy: 0.9263\n",
            "Epoch 135/200\n",
            "390/390 - 28s - loss: 0.3572 - accuracy: 0.9596 - val_loss: 0.5002 - val_accuracy: 0.9262\n",
            "Epoch 136/200\n",
            "390/390 - 28s - loss: 0.3528 - accuracy: 0.9602 - val_loss: 0.5152 - val_accuracy: 0.9203\n",
            "Epoch 137/200\n",
            "390/390 - 28s - loss: 0.3485 - accuracy: 0.9615 - val_loss: 0.5051 - val_accuracy: 0.9225\n",
            "Epoch 138/200\n",
            "390/390 - 28s - loss: 0.3477 - accuracy: 0.9611 - val_loss: 0.4991 - val_accuracy: 0.9246\n",
            "Epoch 139/200\n",
            "390/390 - 28s - loss: 0.3465 - accuracy: 0.9605 - val_loss: 0.5271 - val_accuracy: 0.9195\n",
            "Epoch 140/200\n",
            "390/390 - 28s - loss: 0.3451 - accuracy: 0.9614 - val_loss: 0.4934 - val_accuracy: 0.9270\n",
            "Epoch 141/200\n",
            "390/390 - 28s - loss: 0.3324 - accuracy: 0.9653 - val_loss: 0.4818 - val_accuracy: 0.9306\n",
            "Epoch 142/200\n",
            "390/390 - 28s - loss: 0.3280 - accuracy: 0.9659 - val_loss: 0.4863 - val_accuracy: 0.9286\n",
            "Epoch 143/200\n",
            "390/390 - 28s - loss: 0.3223 - accuracy: 0.9685 - val_loss: 0.4818 - val_accuracy: 0.9323\n",
            "Epoch 144/200\n",
            "390/390 - 28s - loss: 0.3209 - accuracy: 0.9686 - val_loss: 0.4850 - val_accuracy: 0.9294\n",
            "Epoch 145/200\n",
            "390/390 - 28s - loss: 0.3169 - accuracy: 0.9686 - val_loss: 0.4922 - val_accuracy: 0.9289\n",
            "Epoch 146/200\n",
            "390/390 - 28s - loss: 0.3164 - accuracy: 0.9688 - val_loss: 0.4913 - val_accuracy: 0.9278\n",
            "Epoch 147/200\n",
            "390/390 - 28s - loss: 0.3141 - accuracy: 0.9699 - val_loss: 0.4838 - val_accuracy: 0.9300\n",
            "Epoch 148/200\n",
            "390/390 - 28s - loss: 0.3106 - accuracy: 0.9701 - val_loss: 0.4880 - val_accuracy: 0.9292\n",
            "Epoch 149/200\n",
            "390/390 - 28s - loss: 0.3110 - accuracy: 0.9702 - val_loss: 0.4883 - val_accuracy: 0.9270\n",
            "Epoch 150/200\n",
            "390/390 - 28s - loss: 0.3070 - accuracy: 0.9711 - val_loss: 0.4800 - val_accuracy: 0.9297\n",
            "Epoch 151/200\n",
            "390/390 - 28s - loss: 0.3080 - accuracy: 0.9693 - val_loss: 0.4794 - val_accuracy: 0.9303\n",
            "Epoch 152/200\n",
            "390/390 - 28s - loss: 0.3036 - accuracy: 0.9719 - val_loss: 0.4877 - val_accuracy: 0.9299\n",
            "Epoch 153/200\n",
            "390/390 - 28s - loss: 0.3028 - accuracy: 0.9718 - val_loss: 0.4889 - val_accuracy: 0.9289\n",
            "Epoch 154/200\n",
            "390/390 - 28s - loss: 0.3053 - accuracy: 0.9708 - val_loss: 0.4744 - val_accuracy: 0.9318\n",
            "Epoch 155/200\n",
            "390/390 - 28s - loss: 0.3025 - accuracy: 0.9706 - val_loss: 0.4813 - val_accuracy: 0.9299\n",
            "Epoch 156/200\n",
            "390/390 - 28s - loss: 0.3018 - accuracy: 0.9715 - val_loss: 0.4804 - val_accuracy: 0.9293\n",
            "Epoch 157/200\n",
            "390/390 - 28s - loss: 0.2982 - accuracy: 0.9721 - val_loss: 0.4799 - val_accuracy: 0.9293\n",
            "Epoch 158/200\n",
            "390/390 - 28s - loss: 0.2940 - accuracy: 0.9735 - val_loss: 0.4826 - val_accuracy: 0.9280\n",
            "Epoch 159/200\n",
            "390/390 - 28s - loss: 0.2947 - accuracy: 0.9714 - val_loss: 0.4831 - val_accuracy: 0.9292\n",
            "Epoch 160/200\n",
            "390/390 - 28s - loss: 0.2966 - accuracy: 0.9709 - val_loss: 0.4735 - val_accuracy: 0.9314\n",
            "Epoch 161/200\n",
            "390/390 - 28s - loss: 0.2937 - accuracy: 0.9724 - val_loss: 0.4799 - val_accuracy: 0.9297\n",
            "Epoch 162/200\n",
            "390/390 - 28s - loss: 0.2861 - accuracy: 0.9742 - val_loss: 0.4721 - val_accuracy: 0.9313\n",
            "Epoch 163/200\n",
            "390/390 - 28s - loss: 0.2855 - accuracy: 0.9744 - val_loss: 0.4760 - val_accuracy: 0.9311\n",
            "Epoch 164/200\n",
            "390/390 - 28s - loss: 0.2820 - accuracy: 0.9756 - val_loss: 0.4757 - val_accuracy: 0.9312\n",
            "Epoch 165/200\n",
            "390/390 - 28s - loss: 0.2811 - accuracy: 0.9756 - val_loss: 0.4684 - val_accuracy: 0.9334\n",
            "Epoch 166/200\n",
            "390/390 - 28s - loss: 0.2816 - accuracy: 0.9751 - val_loss: 0.4766 - val_accuracy: 0.9311\n",
            "Epoch 167/200\n",
            "390/390 - 28s - loss: 0.2799 - accuracy: 0.9759 - val_loss: 0.4830 - val_accuracy: 0.9292\n",
            "Epoch 168/200\n",
            "390/390 - 28s - loss: 0.2806 - accuracy: 0.9752 - val_loss: 0.4711 - val_accuracy: 0.9325\n",
            "Epoch 169/200\n",
            "390/390 - 28s - loss: 0.2794 - accuracy: 0.9756 - val_loss: 0.4710 - val_accuracy: 0.9302\n",
            "Epoch 170/200\n",
            "390/390 - 28s - loss: 0.2727 - accuracy: 0.9775 - val_loss: 0.4732 - val_accuracy: 0.9322\n",
            "Epoch 171/200\n",
            "390/390 - 28s - loss: 0.2771 - accuracy: 0.9757 - val_loss: 0.4779 - val_accuracy: 0.9303\n",
            "Epoch 172/200\n",
            "390/390 - 28s - loss: 0.2772 - accuracy: 0.9752 - val_loss: 0.4762 - val_accuracy: 0.9321\n",
            "Epoch 173/200\n",
            "390/390 - 28s - loss: 0.2731 - accuracy: 0.9767 - val_loss: 0.4804 - val_accuracy: 0.9307\n",
            "Epoch 174/200\n",
            "390/390 - 28s - loss: 0.2738 - accuracy: 0.9768 - val_loss: 0.4682 - val_accuracy: 0.9333\n",
            "Epoch 175/200\n",
            "390/390 - 28s - loss: 0.2733 - accuracy: 0.9771 - val_loss: 0.4656 - val_accuracy: 0.9338\n",
            "Epoch 176/200\n",
            "390/390 - 28s - loss: 0.2708 - accuracy: 0.9772 - val_loss: 0.4741 - val_accuracy: 0.9325\n",
            "Epoch 177/200\n",
            "390/390 - 28s - loss: 0.2713 - accuracy: 0.9770 - val_loss: 0.4744 - val_accuracy: 0.9309\n",
            "Epoch 178/200\n",
            "390/390 - 28s - loss: 0.2667 - accuracy: 0.9781 - val_loss: 0.4647 - val_accuracy: 0.9324\n",
            "Epoch 179/200\n",
            "390/390 - 28s - loss: 0.2675 - accuracy: 0.9787 - val_loss: 0.4684 - val_accuracy: 0.9330\n",
            "Epoch 180/200\n",
            "390/390 - 28s - loss: 0.2669 - accuracy: 0.9781 - val_loss: 0.4668 - val_accuracy: 0.9340\n",
            "Epoch 181/200\n",
            "390/390 - 28s - loss: 0.2642 - accuracy: 0.9794 - val_loss: 0.4657 - val_accuracy: 0.9330\n",
            "Epoch 182/200\n",
            "390/390 - 28s - loss: 0.2626 - accuracy: 0.9796 - val_loss: 0.4692 - val_accuracy: 0.9322\n",
            "Epoch 183/200\n",
            "390/390 - 28s - loss: 0.2644 - accuracy: 0.9782 - val_loss: 0.4668 - val_accuracy: 0.9324\n",
            "Epoch 184/200\n",
            "390/390 - 28s - loss: 0.2602 - accuracy: 0.9796 - val_loss: 0.4604 - val_accuracy: 0.9344\n",
            "Epoch 185/200\n",
            "390/390 - 28s - loss: 0.2614 - accuracy: 0.9792 - val_loss: 0.4658 - val_accuracy: 0.9336\n",
            "Epoch 186/200\n",
            "390/390 - 28s - loss: 0.2609 - accuracy: 0.9800 - val_loss: 0.4667 - val_accuracy: 0.9321\n",
            "Epoch 187/200\n",
            "390/390 - 28s - loss: 0.2601 - accuracy: 0.9793 - val_loss: 0.4687 - val_accuracy: 0.9331\n",
            "Epoch 188/200\n",
            "390/390 - 28s - loss: 0.2605 - accuracy: 0.9791 - val_loss: 0.4650 - val_accuracy: 0.9338\n",
            "Epoch 189/200\n",
            "390/390 - 28s - loss: 0.2612 - accuracy: 0.9793 - val_loss: 0.4670 - val_accuracy: 0.9324\n",
            "Epoch 190/200\n",
            "390/390 - 28s - loss: 0.2606 - accuracy: 0.9791 - val_loss: 0.4664 - val_accuracy: 0.9345\n",
            "Epoch 191/200\n",
            "390/390 - 28s - loss: 0.2595 - accuracy: 0.9802 - val_loss: 0.4644 - val_accuracy: 0.9333\n",
            "Epoch 192/200\n",
            "390/390 - 28s - loss: 0.2580 - accuracy: 0.9794 - val_loss: 0.4711 - val_accuracy: 0.9328\n",
            "Epoch 193/200\n",
            "390/390 - 28s - loss: 0.2583 - accuracy: 0.9794 - val_loss: 0.4679 - val_accuracy: 0.9335\n",
            "Epoch 194/200\n",
            "390/390 - 28s - loss: 0.2584 - accuracy: 0.9799 - val_loss: 0.4694 - val_accuracy: 0.9325\n",
            "Epoch 195/200\n",
            "390/390 - 28s - loss: 0.2571 - accuracy: 0.9798 - val_loss: 0.4678 - val_accuracy: 0.9323\n",
            "Epoch 196/200\n",
            "390/390 - 28s - loss: 0.2548 - accuracy: 0.9810 - val_loss: 0.4654 - val_accuracy: 0.9325\n",
            "Epoch 197/200\n",
            "390/390 - 28s - loss: 0.2561 - accuracy: 0.9802 - val_loss: 0.4686 - val_accuracy: 0.9327\n",
            "Epoch 198/200\n",
            "390/390 - 28s - loss: 0.2563 - accuracy: 0.9805 - val_loss: 0.4643 - val_accuracy: 0.9322\n",
            "Epoch 199/200\n",
            "390/390 - 28s - loss: 0.2548 - accuracy: 0.9810 - val_loss: 0.4677 - val_accuracy: 0.9328\n",
            "Epoch 200/200\n",
            "390/390 - 28s - loss: 0.2565 - accuracy: 0.9807 - val_loss: 0.4680 - val_accuracy: 0.9332\n",
            "the validation 0/1 loss is:  0.0668\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}